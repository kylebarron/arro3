{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"arro3","text":"<p>A minimal Python library for Apache Arrow, binding to the Rust Arrow implementation.</p>"},{"location":"#why-another-arrow-library","title":"Why another Arrow library?","text":"<p>pyarrow is the reference Arrow implementation in Python, but there are a few reasons for <code>arro3</code> to exist:</p> <ul> <li>Lightweight. pyarrow is 100MB on disk, plus 35MB for its required numpy dependency. <code>arro3-core</code> is around 1MB on disk with no required dependencies.</li> <li>Minimal. The core library (<code>arro3-core</code>) has a very small scope. Other functionality, such as compute kernels, will be distributed in other namespace packages.</li> <li>Modular. The Arrow PyCapsule Interface makes it easier to create small Arrow libraries that communicate via zero-copy data transfer. arro3's Python functions accept Arrow data from any Python Arrow library that implements the PyCapsule interface, including <code>pyarrow</code> and <code>nanoarrow</code>.</li> <li>Extensible. Over time, can connect to compute kernels provided by the Rust Arrow implementation.</li> <li>Compliant. Full support for the Arrow specification, including extension types. (Limited to what the Arrow Rust crate supports, which does not yet support Arrow view types.)</li> </ul>"},{"location":"#drawbacks","title":"Drawbacks","text":"<p>In general, arro3 isn't designed for constructing arrow data from other formats, but should enable users to manage arrow data created by other Arrow-compatible libraries. arro3 does not implement conversion of arbitrary Python objects to Arrow. This is complex and well served by other libraries (e.g. pyarrow).</p>"},{"location":"#using-from-rust","title":"Using from Rust","text":"<p>Refer to pyo3-arrow documentation.</p>"},{"location":"api/compute/","title":"arro3.compute","text":""},{"location":"api/compute/#arro3.compute","title":"arro3.compute","text":""},{"location":"api/compute/#arro3.compute.cast","title":"cast  <code>builtin</code>","text":"<pre><code>cast(\n    input: ArrowArrayExportable | ArrowStreamExportable,\n    to_type: ArrowSchemaExportable,\n) -&gt; Array | ArrayReader\n</code></pre> <p>Cast <code>input</code> to the provided data type and return a new Arrow object with type <code>to_type</code>, if possible.</p> <p>Parameters:</p> <ul> <li> <code>input</code>               (<code>ArrowArrayExportable | ArrowStreamExportable</code>)           \u2013            <p>an Arrow Array, RecordBatch, ChunkedArray, Table, ArrayReader, or RecordBatchReader</p> </li> <li> <code>to_type</code>               (<code>ArrowSchemaExportable</code>)           \u2013            <p>an Arrow DataType, Field, or Schema describing the output type of the cast.</p> </li> </ul>"},{"location":"api/compute/#arro3.compute.list_flatten","title":"list_flatten  <code>builtin</code>","text":"<pre><code>list_flatten(\n    input: ArrowArrayExportable | ArrowStreamExportable,\n) -&gt; Array | ArrayReader\n</code></pre> <p>Unnest this ListArray, LargeListArray or FixedSizeListArray.</p> <p>Parameters:</p> <ul> <li> <code>input</code>               (<code>ArrowArrayExportable | ArrowStreamExportable</code>)           \u2013            <p>description</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Array | ArrayReader</code>           \u2013            <p>description</p> </li> </ul>"},{"location":"api/compute/#arro3.compute.list_offsets","title":"list_offsets  <code>builtin</code>","text":"<pre><code>list_offsets(\n    input: ArrowArrayExportable | ArrowStreamExportable, *, logical: bool = True\n) -&gt; Array | ArrayReader\n</code></pre> <p>Access the offsets of this ListArray or LargeListArray</p> <p>Parameters:</p> <ul> <li> <code>input</code>               (<code>ArrowArrayExportable | ArrowStreamExportable</code>)           \u2013            <p>description</p> </li> <li> <code>physical</code>           \u2013            <p>If False, return the physical (unsliced) offsets of the provided list array. If True, adjust the list offsets for the current array slicing. Defaults to <code>True</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Array | ArrayReader</code>           \u2013            <p>description</p> </li> </ul>"},{"location":"api/compute/#arro3.compute.struct_field","title":"struct_field  <code>builtin</code>","text":"<pre><code>struct_field(\n    values: ArrowArrayExportable, /, indices: int | Sequence[int]\n) -&gt; Array\n</code></pre> <p>Access a column within a StructArray by index</p> <p>Parameters:</p> <ul> <li> <code>values</code>               (<code>ArrowArrayExportable</code>)           \u2013            <p>Argument to compute function.</p> </li> <li> <code>indices</code>               (<code>int | Sequence[int]</code>)           \u2013            <p>List of indices for chained field lookup, for example [4, 1] will look up the second nested field in the fifth outer field.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Array</code>           \u2013            <p>description</p> </li> </ul>"},{"location":"api/compute/#arro3.compute.take","title":"take  <code>builtin</code>","text":"<pre><code>take(values: ArrowArrayExportable, indices: ArrowArrayExportable) -&gt; Array\n</code></pre> <p>Take elements by index from an Array, creating a new Array from those indexes.</p>"},{"location":"api/io/","title":"arro3.io","text":""},{"location":"api/io/#arro3.io","title":"arro3.io","text":""},{"location":"api/io/#arro3.io.infer_csv_schema","title":"infer_csv_schema  <code>builtin</code>","text":"<pre><code>infer_csv_schema(\n    file: IO[bytes] | Path | str,\n    *,\n    has_header: bool | None = None,\n    max_records: int | None = None,\n    delimiter: str | None = None,\n    escape: str | None = None,\n    quote: str | None = None,\n    terminator: str | None = None,\n    comment: str | None = None\n) -&gt; Schema\n</code></pre> <p>Infer a CSV file's schema</p>"},{"location":"api/io/#arro3.io.infer_json_schema","title":"infer_json_schema  <code>builtin</code>","text":"<pre><code>infer_json_schema(\n    file: IO[bytes] | Path | str, *, max_records: int | None = None\n) -&gt; Schema\n</code></pre> <p>Infer a JSON file's schema</p>"},{"location":"api/io/#arro3.io.read_csv","title":"read_csv  <code>builtin</code>","text":"<pre><code>read_csv(\n    file: IO[bytes] | Path | str,\n    schema: ArrowSchemaExportable,\n    *,\n    has_header: bool | None = None,\n    batch_size: int | None = None,\n    delimiter: str | None = None,\n    escape: str | None = None,\n    quote: str | None = None,\n    terminator: str | None = None,\n    comment: str | None = None\n) -&gt; RecordBatchReader\n</code></pre> <p>Read a CSV file to an Arrow RecordBatchReader</p>"},{"location":"api/io/#arro3.io.read_ipc","title":"read_ipc  <code>builtin</code>","text":"<pre><code>read_ipc(file: IO[bytes] | Path | str) -&gt; RecordBatchReader\n</code></pre> <p>Read an Arrow IPC file to an Arrow RecordBatchReader</p>"},{"location":"api/io/#arro3.io.read_ipc_stream","title":"read_ipc_stream  <code>builtin</code>","text":"<pre><code>read_ipc_stream(file: IO[bytes] | Path | str) -&gt; RecordBatchReader\n</code></pre> <p>Read an Arrow IPC Stream file to an Arrow RecordBatchReader</p>"},{"location":"api/io/#arro3.io.read_json","title":"read_json  <code>builtin</code>","text":"<pre><code>read_json(\n    file: IO[bytes] | Path | str,\n    schema: ArrowSchemaExportable,\n    *,\n    batch_size: int | None = None\n) -&gt; RecordBatchReader\n</code></pre> <p>Read a JSON file to an Arrow RecordBatchReader</p>"},{"location":"api/io/#arro3.io.read_parquet","title":"read_parquet  <code>builtin</code>","text":"<pre><code>read_parquet(file: Path | str) -&gt; RecordBatchReader\n</code></pre> <p>Read a Parquet file to an Arrow RecordBatchReader</p> <p>Parameters:</p> <ul> <li> <code>file</code>               (<code>Path | str</code>)           \u2013            <p>description</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RecordBatchReader</code>           \u2013            <p>description</p> </li> </ul>"},{"location":"api/io/#arro3.io.write_csv","title":"write_csv  <code>builtin</code>","text":"<pre><code>write_csv(\n    data: ArrowStreamExportable | ArrowArrayExportable,\n    file: IO[bytes] | Path | str,\n    *,\n    header: bool | None = None,\n    delimiter: str | None = None,\n    escape: str | None = None,\n    quote: str | None = None,\n    date_format: str | None = None,\n    datetime_format: str | None = None,\n    time_format: str | None = None,\n    timestamp_format: str | None = None,\n    timestamp_tz_format: str | None = None,\n    null: str | None = None\n) -&gt; None\n</code></pre> <p>Write an Arrow Table or stream to a CSV file</p>"},{"location":"api/io/#arro3.io.write_ipc","title":"write_ipc  <code>builtin</code>","text":"<pre><code>write_ipc(\n    data: ArrowStreamExportable | ArrowArrayExportable,\n    file: IO[bytes] | Path | str,\n) -&gt; None\n</code></pre> <p>Write an Arrow Table or stream to an IPC File</p>"},{"location":"api/io/#arro3.io.write_ipc_stream","title":"write_ipc_stream  <code>builtin</code>","text":"<pre><code>write_ipc_stream(\n    data: ArrowStreamExportable | ArrowArrayExportable,\n    file: IO[bytes] | Path | str,\n) -&gt; None\n</code></pre> <p>Write an Arrow Table or stream to an IPC Stream</p>"},{"location":"api/io/#arro3.io.write_json","title":"write_json  <code>builtin</code>","text":"<pre><code>write_json(\n    data: ArrowStreamExportable | ArrowArrayExportable,\n    file: IO[bytes] | Path | str,\n    *,\n    explicit_nulls: bool | None = None\n) -&gt; None\n</code></pre> <p>Write an Arrow Table or stream to a JSON file</p>"},{"location":"api/io/#arro3.io.write_ndjson","title":"write_ndjson  <code>builtin</code>","text":"<pre><code>write_ndjson(\n    data: ArrowStreamExportable | ArrowArrayExportable,\n    file: IO[bytes] | Path | str,\n    *,\n    explicit_nulls: bool | None = None\n) -&gt; None\n</code></pre> <p>Write an Arrow Table or stream to a newline-delimited JSON file</p>"},{"location":"api/io/#arro3.io.write_parquet","title":"write_parquet  <code>builtin</code>","text":"<pre><code>write_parquet(\n    data: ArrowStreamExportable | ArrowArrayExportable,\n    file: IO[bytes] | Path | str,\n    *,\n    bloom_filter_enabled: bool | None = None,\n    bloom_filter_fpp: float | None = None,\n    bloom_filter_ndv: int | None = None,\n    column_compression: dict[ParquetColumnPath, ParquetCompression]\n    | None = None,\n    column_dictionary_enabled: dict[ParquetColumnPath, bool] | None = None,\n    column_encoding: dict[ParquetColumnPath, ParquetEncoding] | None = None,\n    column_max_statistics_size: dict[ParquetColumnPath, int] | None = None,\n    compression: ParquetCompression | None = None,\n    created_by: str | None = None,\n    data_page_row_count_limit: int | None = None,\n    data_page_size_limit: int | None = None,\n    dictionary_enabled: bool | None = None,\n    dictionary_page_size_limit: int | None = None,\n    encoding: ParquetEncoding | None = None,\n    key_value_metadata: dict[str, str] | None = None,\n    max_row_group_size: int | None = None,\n    max_statistics_size: int | None = None,\n    write_batch_size: int | None = None,\n    writer_version: Literal[\"parquet_1_0\", \"parquet_2_0\"] | None = None\n) -&gt; None\n</code></pre> <p>Write an Arrow Table or stream to a Parquet file.</p> <p>Parameters:</p> <ul> <li> <code>data</code>               (<code>ArrowStreamExportable | ArrowArrayExportable</code>)           \u2013            <p>The Arrow Table, RecordBatchReader, or RecordBatch to write to Parquet.</p> </li> <li> <code>file</code>               (<code>IO[bytes] | Path | str</code>)           \u2013            <p>The output file.</p> </li> </ul> <p>Other Parameters:</p> <ul> <li> <code>bloom_filter_enabled</code>               (<code>bool | None</code>)           \u2013            <p>Sets if bloom filter is enabled by default for all columns (defaults to <code>false</code>).</p> </li> <li> <code>bloom_filter_fpp</code>               (<code>float | None</code>)           \u2013            <p>Sets the default target bloom filter false positive probability (fpp) for all columns (defaults to <code>0.05</code>).</p> </li> <li> <code>bloom_filter_ndv</code>               (<code>int | None</code>)           \u2013            <p>Sets default number of distinct values (ndv) for bloom filter for all columns (defaults to <code>1_000_000</code>).</p> </li> <li> <code>column_compression</code>               (<code>dict[ParquetColumnPath, ParquetCompression] | None</code>)           \u2013            <p>Sets compression codec for a specific column. Takes precedence over <code>compression</code>.</p> </li> <li> <code>column_dictionary_enabled</code>               (<code>dict[ParquetColumnPath, bool] | None</code>)           \u2013            <p>Sets flag to enable/disable dictionary encoding for a specific column. Takes precedence over <code>dictionary_enabled</code>.</p> </li> <li> <code>column_encoding</code>               (<code>dict[ParquetColumnPath, ParquetEncoding] | None</code>)           \u2013            <p>Sets encoding for a specific column. Takes precedence over <code>encoding</code>.</p> </li> <li> <code>column_max_statistics_size</code>               (<code>dict[ParquetColumnPath, int] | None</code>)           \u2013            <p>Sets max size for statistics for a specific column. Takes precedence over <code>max_statistics_size</code>.</p> </li> <li> <code>compression</code>               (<code>ParquetCompression | None</code>)           \u2013            <p>Sets default compression codec for all columns (default to <code>uncompressed</code>). Note that you can pass in a custom compression level with a string like <code>\"zstd(3)\"</code> or <code>\"gzip(9)\"</code> or <code>\"brotli(3)\"</code>.</p> </li> <li> <code>created_by</code>               (<code>str | None</code>)           \u2013            <p>Sets \"created by\" property (defaults to <code>parquet-rs version &lt;VERSION&gt;</code>).</p> </li> <li> <code>data_page_row_count_limit</code>               (<code>int | None</code>)           \u2013            <p>Sets best effort maximum number of rows in a data page (defaults to <code>20_000</code>).</p> <p>The parquet writer will attempt to limit the number of rows in each <code>DataPage</code> to this value. Reducing this value will result in larger parquet files, but may improve the effectiveness of page index based predicate pushdown during reading.</p> <p>Note: this is a best effort limit based on value of <code>set_write_batch_size</code>.</p> </li> <li> <code>data_page_size_limit</code>               (<code>int | None</code>)           \u2013            <p>Sets best effort maximum size of a data page in bytes (defaults to <code>1024 * 1024</code>).</p> <p>The parquet writer will attempt to limit the sizes of each <code>DataPage</code> to this many bytes. Reducing this value will result in larger parquet files, but may improve the effectiveness of page index based predicate pushdown during reading.</p> <p>Note: this is a best effort limit based on value of <code>set_write_batch_size</code>.</p> </li> <li> <code>dictionary_enabled</code>               (<code>bool | None</code>)           \u2013            <p>Sets default flag to enable/disable dictionary encoding for all columns (defaults to <code>True</code>).</p> </li> <li> <code>dictionary_page_size_limit</code>               (<code>int | None</code>)           \u2013            <p>Sets best effort maximum dictionary page size, in bytes (defaults to <code>1024 * 1024</code>).</p> <p>The parquet writer will attempt to limit the size of each <code>DataPage</code> used to store dictionaries to this many bytes. Reducing this value will result in larger parquet files, but may improve the effectiveness of page index based predicate pushdown during reading.</p> <p>Note: this is a best effort limit based on value of <code>set_write_batch_size</code>.</p> </li> <li> <code>encoding</code>               (<code>ParquetEncoding | None</code>)           \u2013            <p>Sets default encoding for all columns.</p> <p>If dictionary is not enabled, this is treated as a primary encoding for all columns. In case when dictionary is enabled for any column, this value is considered to be a fallback encoding for that column.</p> </li> <li> <code>key_value_metadata</code>               (<code>dict[str, str] | None</code>)           \u2013            <p>Sets \"key_value_metadata\" property (defaults to <code>None</code>).</p> </li> <li> <code>max_row_group_size</code>               (<code>int | None</code>)           \u2013            <p>Sets maximum number of rows in a row group (defaults to <code>1024 * 1024</code>).</p> </li> <li> <code>max_statistics_size</code>               (<code>int | None</code>)           \u2013            <p>Sets default max statistics size for all columns (defaults to <code>4096</code>).</p> </li> <li> <code>write_batch_size</code>               (<code>int | None</code>)           \u2013            <p>Sets write batch size (defaults to 1024).</p> <p>For performance reasons, data for each column is written in batches of this size.</p> <p>Additional limits such as such as <code>set_data_page_row_count_limit</code> are checked between batches, and thus the write batch size value acts as an upper-bound on the enforcement granularity of other limits.</p> </li> <li> <code>writer_version</code>               (<code>Literal['parquet_1_0', 'parquet_2_0'] | None</code>)           \u2013            <p>Sets the <code>WriterVersion</code> written into the parquet metadata (defaults to <code>\"parquet_1_0\"</code>). This value can determine what features some readers will support.</p> </li> </ul>"},{"location":"api/core/array-reader/","title":"ArrayReader","text":""},{"location":"api/core/array-reader/#arro3.core.ArrayReader","title":"arro3.core.ArrayReader","text":"<p>A stream of Arrow <code>Array</code>s.</p> <p>This is similar to the <code>RecordBatchReader</code> but each item yielded from the stream is an <code>Array</code>, not a <code>RecordBatch</code>.</p>"},{"location":"api/core/array-reader/#arro3.core.ArrayReader.closed","title":"closed","text":"<pre><code>closed: bool = &lt;attribute 'closed' of 'arro3.core._core.ArrayReader' objects&gt;\n</code></pre>"},{"location":"api/core/array-reader/#arro3.core.ArrayReader.field","title":"field","text":"<pre><code>field: Field = &lt;attribute 'field' of 'arro3.core._core.ArrayReader' objects&gt;\n</code></pre>"},{"location":"api/core/array-reader/#arro3.core.ArrayReader.__arrow_c_stream__","title":"__arrow_c_stream__  <code>method descriptor</code>","text":"<pre><code>__arrow_c_stream__(requested_schema: object | None = None) -&gt; object\n</code></pre> <p>An implementation of the Arrow PyCapsule Interface. This dunder method should not be called directly, but enables zero-copy data transfer to other Python libraries that understand Arrow memory.</p> <p>For example, you can call <code>pyarrow.table()</code> to convert this ArrayReader to a pyarrow table, without copying memory.</p>"},{"location":"api/core/array-reader/#arro3.core.ArrayReader.from_arrow","title":"from_arrow  <code>builtin</code>","text":"<pre><code>from_arrow(input: ArrowArrayExportable | ArrowStreamExportable) -&gt; ArrayReader\n</code></pre> <p>Construct this from an existing Arrow object.</p> <p>It can be called on anything that exports the Arrow stream interface (has an <code>__arrow_c_stream__</code> method), such as a <code>Table</code> or <code>ArrayReader</code>.</p>"},{"location":"api/core/array-reader/#arro3.core.ArrayReader.from_arrow_pycapsule","title":"from_arrow_pycapsule  <code>builtin</code>","text":"<pre><code>from_arrow_pycapsule(capsule) -&gt; ArrayReader\n</code></pre> <p>Construct this object from a bare Arrow PyCapsule</p>"},{"location":"api/core/array-reader/#arro3.core.ArrayReader.from_stream","title":"from_stream  <code>builtin</code>","text":"<pre><code>from_stream(data: ArrowStreamExportable) -&gt; ArrayReader\n</code></pre> <p>Construct this from an existing Arrow object.</p> <p>This is an alias of and has the same behavior as <code>from_arrow</code>, but is included for parity with <code>pyarrow.RecordBatchReader</code>.</p>"},{"location":"api/core/array-reader/#arro3.core.ArrayReader.read_all","title":"read_all  <code>method descriptor</code>","text":"<pre><code>read_all() -&gt; ChunkedArray\n</code></pre> <p>Read all batches from this stream into a ChunkedArray.</p>"},{"location":"api/core/array-reader/#arro3.core.ArrayReader.read_next_array","title":"read_next_array  <code>method descriptor</code>","text":"<pre><code>read_next_array() -&gt; Array\n</code></pre> <p>Read the next array from this stream.</p>"},{"location":"api/core/array/","title":"Array","text":""},{"location":"api/core/array/#arro3.core.Array","title":"arro3.core.Array","text":""},{"location":"api/core/array/#arro3.core.Array.field","title":"field","text":"<pre><code>field: Field = &lt;attribute 'field' of 'arro3.core._core.Array' objects&gt;\n</code></pre>"},{"location":"api/core/array/#arro3.core.Array.nbytes","title":"nbytes","text":"<pre><code>nbytes: int = &lt;attribute 'nbytes' of 'arro3.core._core.Array' objects&gt;\n</code></pre>"},{"location":"api/core/array/#arro3.core.Array.type","title":"type","text":"<pre><code>type: DataType = &lt;attribute 'type' of 'arro3.core._core.Array' objects&gt;\n</code></pre>"},{"location":"api/core/array/#arro3.core.Array.__arrow_c_array__","title":"__arrow_c_array__  <code>method descriptor</code>","text":"<pre><code>__arrow_c_array__(\n    requested_schema: object | None = None,\n) -&gt; tuple[object, object]\n</code></pre> <p>An implementation of the Arrow PyCapsule Interface. This dunder method should not be called directly, but enables zero-copy data transfer to other Python libraries that understand Arrow memory.</p> <p>For example, you can call <code>pyarrow.array()</code> to convert this array into a pyarrow array, without copying memory.</p>"},{"location":"api/core/array/#arro3.core.Array.cast","title":"cast  <code>method descriptor</code>","text":"<pre><code>cast(target_type: ArrowSchemaExportable) -&gt; Array\n</code></pre> <p>Cast array values to another data type</p> <p>Parameters:</p> <ul> <li> <code>target_type</code>               (<code>ArrowSchemaExportable</code>)           \u2013            <p>Type to cast array to.</p> </li> </ul>"},{"location":"api/core/array/#arro3.core.Array.from_arrow","title":"from_arrow  <code>builtin</code>","text":"<pre><code>from_arrow(input: ArrowArrayExportable | ArrowStreamExportable) -&gt; Array\n</code></pre> <p>Construct this object from an existing Arrow object.</p> <p>It can be called on anything that exports the Arrow data interface (<code>__arrow_c_array__</code>).</p> <p>Parameters:</p> <ul> <li> <code>input</code>               (<code>ArrowArrayExportable | ArrowStreamExportable</code>)           \u2013            <p>Arrow array to use for constructing this object</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Array</code>           \u2013            <p>Self</p> </li> </ul>"},{"location":"api/core/array/#arro3.core.Array.from_arrow_pycapsule","title":"from_arrow_pycapsule  <code>builtin</code>","text":"<pre><code>from_arrow_pycapsule(schema_capsule, array_capsule) -&gt; Array\n</code></pre> <p>Construct this object from bare Arrow PyCapsules</p>"},{"location":"api/core/array/#arro3.core.Array.from_numpy","title":"from_numpy  <code>builtin</code>","text":"<pre><code>from_numpy(array: ndarray) -&gt; Array\n</code></pre> <p>Construct an Array from a numpy ndarray</p>"},{"location":"api/core/array/#arro3.core.Array.slice","title":"slice  <code>method descriptor</code>","text":"<pre><code>slice(offset: int = 0, length: int | None = None) -&gt; Array\n</code></pre> <p>Compute zero-copy slice of this array.</p> <p>Parameters:</p> <ul> <li> <code>offset</code>               (<code>int</code>, default:                   <code>0</code> )           \u2013            <p>Defaults to 0.</p> </li> <li> <code>length</code>               (<code>int | None</code>, default:                   <code>None</code> )           \u2013            <p>Defaults to None.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Array</code>           \u2013            <p>The sliced array</p> </li> </ul>"},{"location":"api/core/array/#arro3.core.Array.to_numpy","title":"to_numpy  <code>method descriptor</code>","text":"<pre><code>to_numpy() -&gt; NDArray\n</code></pre> <p>Return a numpy copy of this array.</p>"},{"location":"api/core/chunked-array/","title":"ChunkedArray","text":""},{"location":"api/core/chunked-array/#arro3.core.ChunkedArray","title":"arro3.core.ChunkedArray","text":""},{"location":"api/core/chunked-array/#arro3.core.ChunkedArray.chunks","title":"chunks","text":"<pre><code>chunks: list[Array] = &lt;attribute 'chunks' of 'arro3.core._core.ChunkedArray' objects&gt;\n</code></pre>"},{"location":"api/core/chunked-array/#arro3.core.ChunkedArray.nbytes","title":"nbytes","text":"<pre><code>nbytes: int = &lt;attribute 'nbytes' of 'arro3.core._core.ChunkedArray' objects&gt;\n</code></pre>"},{"location":"api/core/chunked-array/#arro3.core.ChunkedArray.null_count","title":"null_count","text":"<pre><code>null_count: int = &lt;attribute 'null_count' of 'arro3.core._core.ChunkedArray' objects&gt;\n</code></pre>"},{"location":"api/core/chunked-array/#arro3.core.ChunkedArray.num_chunks","title":"num_chunks","text":"<pre><code>num_chunks: int = &lt;attribute 'num_chunks' of 'arro3.core._core.ChunkedArray' objects&gt;\n</code></pre>"},{"location":"api/core/chunked-array/#arro3.core.ChunkedArray.type","title":"type","text":"<pre><code>type: DataType = &lt;attribute 'type' of 'arro3.core._core.ChunkedArray' objects&gt;\n</code></pre>"},{"location":"api/core/chunked-array/#arro3.core.ChunkedArray.__arrow_c_stream__","title":"__arrow_c_stream__  <code>method descriptor</code>","text":"<pre><code>__arrow_c_stream__(requested_schema: object | None = None) -&gt; object\n</code></pre> <p>An implementation of the Arrow PyCapsule Interface. This dunder method should not be called directly, but enables zero-copy data transfer to other Python libraries that understand Arrow memory.</p> <p>For example (as of pyarrow v16), you can call <code>pyarrow.chunked_array()</code> to convert this array into a pyarrow array, without copying memory.</p>"},{"location":"api/core/chunked-array/#arro3.core.ChunkedArray.cast","title":"cast  <code>method descriptor</code>","text":"<pre><code>cast(target_type: ArrowSchemaExportable) -&gt; ChunkedArray\n</code></pre> <p>Cast array values to another data type</p> <p>Parameters:</p> <ul> <li> <code>target_type</code>               (<code>ArrowSchemaExportable</code>)           \u2013            <p>Type to cast array to.</p> </li> </ul>"},{"location":"api/core/chunked-array/#arro3.core.ChunkedArray.chunk","title":"chunk  <code>method descriptor</code>","text":"<pre><code>chunk(i: int) -&gt; Array\n</code></pre> <p>Select a chunk by its index.</p> <p>Parameters:</p> <ul> <li> <code>i</code>               (<code>int</code>)           \u2013            <p>chunk index.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Array</code>           \u2013            <p>new Array.</p> </li> </ul>"},{"location":"api/core/chunked-array/#arro3.core.ChunkedArray.combine_chunks","title":"combine_chunks  <code>method descriptor</code>","text":"<pre><code>combine_chunks() -&gt; Array\n</code></pre> <p>Flatten this ChunkedArray into a single non-chunked array.</p>"},{"location":"api/core/chunked-array/#arro3.core.ChunkedArray.equals","title":"equals  <code>method descriptor</code>","text":"<pre><code>equals(other: ArrowStreamExportable) -&gt; bool\n</code></pre> <p>Return whether the contents of two chunked arrays are equal.</p>"},{"location":"api/core/chunked-array/#arro3.core.ChunkedArray.from_arrow","title":"from_arrow  <code>builtin</code>","text":"<pre><code>from_arrow(input: ArrowArrayExportable | ArrowStreamExportable) -&gt; ChunkedArray\n</code></pre> <p>Construct this from an existing Arrow object.</p> <p>It can be called on anything that exports the Arrow stream interface (has an <code>__arrow_c_stream__</code> method). All batches from the stream will be materialized in memory.</p>"},{"location":"api/core/chunked-array/#arro3.core.ChunkedArray.from_arrow_pycapsule","title":"from_arrow_pycapsule  <code>builtin</code>","text":"<pre><code>from_arrow_pycapsule(capsule) -&gt; ChunkedArray\n</code></pre> <p>Construct this object from a bare Arrow PyCapsule</p>"},{"location":"api/core/chunked-array/#arro3.core.ChunkedArray.length","title":"length  <code>method descriptor</code>","text":"<pre><code>length() -&gt; int\n</code></pre> <p>Return length of a ChunkedArray.</p>"},{"location":"api/core/chunked-array/#arro3.core.ChunkedArray.slice","title":"slice  <code>method descriptor</code>","text":"<pre><code>slice(offset: int = 0, length: int | None = None) -&gt; ChunkedArray\n</code></pre> <p>Compute zero-copy slice of this ChunkedArray</p> <p>Parameters:</p> <ul> <li> <code>offset</code>               (<code>int</code>, default:                   <code>0</code> )           \u2013            <p>Offset from start of array to slice. Defaults to 0.</p> </li> <li> <code>length</code>               (<code>int | None</code>, default:                   <code>None</code> )           \u2013            <p>Length of slice (default is until end of batch starting from offset).</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ChunkedArray</code>           \u2013            <p>New ChunkedArray</p> </li> </ul>"},{"location":"api/core/chunked-array/#arro3.core.ChunkedArray.to_numpy","title":"to_numpy  <code>method descriptor</code>","text":"<pre><code>to_numpy() -&gt; NDArray\n</code></pre> <p>Copy this array to a <code>numpy</code> NDArray</p>"},{"location":"api/core/datatype/","title":"DataType","text":""},{"location":"api/core/datatype/#arro3.core.DataType","title":"arro3.core.DataType","text":"<p>An Arrow DataType.</p>"},{"location":"api/core/datatype/#arro3.core.DataType.bit_width","title":"bit_width","text":"<pre><code>bit_width: int | None = &lt;attribute 'bit_width' of 'arro3.core._core.DataType' objects&gt;\n</code></pre>"},{"location":"api/core/datatype/#arro3.core.DataType.list_size","title":"list_size","text":"<pre><code>list_size: int | None = &lt;attribute 'list_size' of 'arro3.core._core.DataType' objects&gt;\n</code></pre>"},{"location":"api/core/datatype/#arro3.core.DataType.num_fields","title":"num_fields","text":"<pre><code>num_fields: int = &lt;attribute 'num_fields' of 'arro3.core._core.DataType' objects&gt;\n</code></pre>"},{"location":"api/core/datatype/#arro3.core.DataType.value_type","title":"value_type","text":"<pre><code>value_type: DataType | None = &lt;attribute 'value_type' of 'arro3.core._core.DataType' objects&gt;\n</code></pre>"},{"location":"api/core/datatype/#arro3.core.DataType.__arrow_c_schema__","title":"__arrow_c_schema__  <code>method descriptor</code>","text":"<pre><code>__arrow_c_schema__() -&gt; object\n</code></pre> <p>An implementation of the Arrow PyCapsule Interface. This dunder method should not be called directly, but enables zero-copy data transfer to other Python libraries that understand Arrow memory.</p> <p>For example, you can call <code>pyarrow.field()</code> to convert this array into a pyarrow field, without copying memory.</p>"},{"location":"api/core/datatype/#arro3.core.DataType.binary","title":"binary  <code>builtin</code>","text":"<pre><code>binary(length: int | None = None) -&gt; DataType\n</code></pre> <p>Create variable-length or fixed size binary type.</p> <p>Parameters:</p> <ul> <li> <code>length</code>               (<code>int | None</code>, default:                   <code>None</code> )           \u2013            <p>If length is <code>None</code> then return a variable length binary type. If length is provided, then return a fixed size binary type of width <code>length</code>. Defaults to None.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>DataType</code>           \u2013            <p>description</p> </li> </ul>"},{"location":"api/core/datatype/#arro3.core.DataType.binary_view","title":"binary_view  <code>builtin</code>","text":"<pre><code>binary_view() -&gt; DataType\n</code></pre> <p>Create a variable-length binary view type.</p>"},{"location":"api/core/datatype/#arro3.core.DataType.bool","title":"bool  <code>builtin</code>","text":"<pre><code>bool() -&gt; DataType\n</code></pre> <p>Create instance of boolean type.</p>"},{"location":"api/core/datatype/#arro3.core.DataType.date32","title":"date32  <code>builtin</code>","text":"<pre><code>date32() -&gt; DataType\n</code></pre> <p>Create instance of 32-bit date (days since UNIX epoch 1970-01-01).</p>"},{"location":"api/core/datatype/#arro3.core.DataType.date64","title":"date64  <code>builtin</code>","text":"<pre><code>date64() -&gt; DataType\n</code></pre> <p>Create instance of 64-bit date (milliseconds since UNIX epoch 1970-01-01).</p>"},{"location":"api/core/datatype/#arro3.core.DataType.decimal128","title":"decimal128  <code>builtin</code>","text":"<pre><code>decimal128(precision: int, scale: int) -&gt; DataType\n</code></pre> <p>Create decimal type with precision and scale and 128-bit width.</p> <p>Arrow decimals are fixed-point decimal numbers encoded as a scaled integer. The precision is the number of significant digits that the decimal type can represent; the scale is the number of digits after the decimal point (note the scale can be negative).</p> <p>As an example, <code>decimal128(7, 3)</code> can exactly represent the numbers 1234.567 and -1234.567 (encoded internally as the 128-bit integers 1234567 and -1234567, respectively), but neither 12345.67 nor 123.4567.</p> <p><code>decimal128(5, -3)</code> can exactly represent the number 12345000 (encoded internally as the 128-bit integer 12345), but neither 123450000 nor 1234500.</p> <p>If you need a precision higher than 38 significant digits, consider using <code>decimal256</code>.</p> <p>Parameters:</p> <ul> <li> <code>precision</code>               (<code>int</code>)           \u2013            <p>Must be between 1 and 38 scale: description</p> </li> </ul>"},{"location":"api/core/datatype/#arro3.core.DataType.decimal256","title":"decimal256  <code>builtin</code>","text":"<pre><code>decimal256(precision: int, scale: int) -&gt; DataType\n</code></pre> <p>Create decimal type with precision and scale and 256-bit width.</p>"},{"location":"api/core/datatype/#arro3.core.DataType.dictionary","title":"dictionary  <code>builtin</code>","text":"<pre><code>dictionary(\n    index_type: ArrowSchemaExportable, value_type: ArrowSchemaExportable\n) -&gt; DataType\n</code></pre> <p>Dictionary (categorical, or simply encoded) type.</p> <p>Parameters:</p> <ul> <li> <code>index_type</code>               (<code>ArrowSchemaExportable</code>)           \u2013            <p>description</p> </li> <li> <code>value_type</code>               (<code>ArrowSchemaExportable</code>)           \u2013            <p>description</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>DataType</code>           \u2013            <p>description</p> </li> </ul>"},{"location":"api/core/datatype/#arro3.core.DataType.duration","title":"duration  <code>builtin</code>","text":"<pre><code>duration(unit: Literal['s', 'ms', 'us', 'ns']) -&gt; DataType\n</code></pre> <p>Create instance of a duration type with unit resolution.</p> <p>Parameters:</p> <ul> <li> <code>unit</code>               (<code>Literal['s', 'ms', 'us', 'ns']</code>)           \u2013            <p>one of <code>'s'</code> [second], <code>'ms'</code> [millisecond], <code>'us'</code> [microsecond], or <code>'ns'</code> [nanosecond]</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>DataType</code>           \u2013            <p>description</p> </li> </ul>"},{"location":"api/core/datatype/#arro3.core.DataType.equals","title":"equals  <code>method descriptor</code>","text":"<pre><code>equals(other: ArrowSchemaExportable, *, check_metadata: bool = False) -&gt; bool\n</code></pre> <p>Return true if type is equivalent to passed value.</p> <p>Parameters:</p> <ul> <li> <code>other</code>               (<code>ArrowSchemaExportable</code>)           \u2013            <p>description</p> </li> <li> <code>check_metadata</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether nested Field metadata equality should be checked as well. Defaults to False.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bool</code>           \u2013            <p>description</p> </li> </ul>"},{"location":"api/core/datatype/#arro3.core.DataType.float16","title":"float16  <code>builtin</code>","text":"<pre><code>float16() -&gt; DataType\n</code></pre> <p>Create half-precision floating point type.</p>"},{"location":"api/core/datatype/#arro3.core.DataType.float32","title":"float32  <code>builtin</code>","text":"<pre><code>float32() -&gt; DataType\n</code></pre> <p>Create single-precision floating point type.</p>"},{"location":"api/core/datatype/#arro3.core.DataType.float64","title":"float64  <code>builtin</code>","text":"<pre><code>float64() -&gt; DataType\n</code></pre> <p>Create double-precision floating point type.</p>"},{"location":"api/core/datatype/#arro3.core.DataType.from_arrow","title":"from_arrow  <code>builtin</code>","text":"<pre><code>from_arrow(input: ArrowSchemaExportable) -&gt; DataType\n</code></pre> <p>Construct this from an existing Arrow object.</p> <p>It can be called on anything that exports the Arrow schema interface (has an <code>__arrow_c_schema__</code> method).</p>"},{"location":"api/core/datatype/#arro3.core.DataType.from_arrow_pycapsule","title":"from_arrow_pycapsule  <code>builtin</code>","text":"<pre><code>from_arrow_pycapsule(capsule) -&gt; DataType\n</code></pre> <p>Construct this object from a bare Arrow PyCapsule</p>"},{"location":"api/core/datatype/#arro3.core.DataType.int16","title":"int16  <code>builtin</code>","text":"<pre><code>int16() -&gt; DataType\n</code></pre> <p>Create instance of signed int16 type.</p>"},{"location":"api/core/datatype/#arro3.core.DataType.int32","title":"int32  <code>builtin</code>","text":"<pre><code>int32() -&gt; DataType\n</code></pre> <p>Create instance of signed int32 type.</p>"},{"location":"api/core/datatype/#arro3.core.DataType.int64","title":"int64  <code>builtin</code>","text":"<pre><code>int64() -&gt; DataType\n</code></pre> <p>Create instance of signed int64 type.</p>"},{"location":"api/core/datatype/#arro3.core.DataType.int8","title":"int8  <code>builtin</code>","text":"<pre><code>int8() -&gt; DataType\n</code></pre> <p>Create instance of signed int8 type.</p>"},{"location":"api/core/datatype/#arro3.core.DataType.is_binary","title":"is_binary  <code>staticmethod</code>","text":"<pre><code>is_binary(t: ArrowSchemaExportable) -&gt; bool\n</code></pre>"},{"location":"api/core/datatype/#arro3.core.DataType.is_binary_view","title":"is_binary_view  <code>staticmethod</code>","text":"<pre><code>is_binary_view(t: ArrowSchemaExportable) -&gt; bool\n</code></pre>"},{"location":"api/core/datatype/#arro3.core.DataType.is_boolean","title":"is_boolean  <code>staticmethod</code>","text":"<pre><code>is_boolean(t: ArrowSchemaExportable) -&gt; bool\n</code></pre>"},{"location":"api/core/datatype/#arro3.core.DataType.is_date","title":"is_date  <code>staticmethod</code>","text":"<pre><code>is_date(t: ArrowSchemaExportable) -&gt; bool\n</code></pre>"},{"location":"api/core/datatype/#arro3.core.DataType.is_date32","title":"is_date32  <code>staticmethod</code>","text":"<pre><code>is_date32(t: ArrowSchemaExportable) -&gt; bool\n</code></pre>"},{"location":"api/core/datatype/#arro3.core.DataType.is_date64","title":"is_date64  <code>staticmethod</code>","text":"<pre><code>is_date64(t: ArrowSchemaExportable) -&gt; bool\n</code></pre>"},{"location":"api/core/datatype/#arro3.core.DataType.is_decimal","title":"is_decimal  <code>staticmethod</code>","text":"<pre><code>is_decimal(t: ArrowSchemaExportable) -&gt; bool\n</code></pre>"},{"location":"api/core/datatype/#arro3.core.DataType.is_decimal128","title":"is_decimal128  <code>staticmethod</code>","text":"<pre><code>is_decimal128(t: ArrowSchemaExportable) -&gt; bool\n</code></pre>"},{"location":"api/core/datatype/#arro3.core.DataType.is_decimal256","title":"is_decimal256  <code>staticmethod</code>","text":"<pre><code>is_decimal256(t: ArrowSchemaExportable) -&gt; bool\n</code></pre>"},{"location":"api/core/datatype/#arro3.core.DataType.is_dictionary","title":"is_dictionary  <code>staticmethod</code>","text":"<pre><code>is_dictionary(t: ArrowSchemaExportable) -&gt; bool\n</code></pre>"},{"location":"api/core/datatype/#arro3.core.DataType.is_dictionary_key_type","title":"is_dictionary_key_type  <code>staticmethod</code>","text":"<pre><code>is_dictionary_key_type(t: ArrowSchemaExportable) -&gt; bool\n</code></pre>"},{"location":"api/core/datatype/#arro3.core.DataType.is_duration","title":"is_duration  <code>staticmethod</code>","text":"<pre><code>is_duration(t: ArrowSchemaExportable) -&gt; bool\n</code></pre>"},{"location":"api/core/datatype/#arro3.core.DataType.is_fixed_size_binary","title":"is_fixed_size_binary  <code>staticmethod</code>","text":"<pre><code>is_fixed_size_binary(t: ArrowSchemaExportable) -&gt; bool\n</code></pre>"},{"location":"api/core/datatype/#arro3.core.DataType.is_fixed_size_list","title":"is_fixed_size_list  <code>staticmethod</code>","text":"<pre><code>is_fixed_size_list(t: ArrowSchemaExportable) -&gt; bool\n</code></pre>"},{"location":"api/core/datatype/#arro3.core.DataType.is_float16","title":"is_float16  <code>staticmethod</code>","text":"<pre><code>is_float16(t: ArrowSchemaExportable) -&gt; bool\n</code></pre>"},{"location":"api/core/datatype/#arro3.core.DataType.is_float32","title":"is_float32  <code>staticmethod</code>","text":"<pre><code>is_float32(t: ArrowSchemaExportable) -&gt; bool\n</code></pre>"},{"location":"api/core/datatype/#arro3.core.DataType.is_float64","title":"is_float64  <code>staticmethod</code>","text":"<pre><code>is_float64(t: ArrowSchemaExportable) -&gt; bool\n</code></pre>"},{"location":"api/core/datatype/#arro3.core.DataType.is_floating","title":"is_floating  <code>staticmethod</code>","text":"<pre><code>is_floating(t: ArrowSchemaExportable) -&gt; bool\n</code></pre>"},{"location":"api/core/datatype/#arro3.core.DataType.is_int16","title":"is_int16  <code>staticmethod</code>","text":"<pre><code>is_int16(t: ArrowSchemaExportable) -&gt; bool\n</code></pre>"},{"location":"api/core/datatype/#arro3.core.DataType.is_int32","title":"is_int32  <code>staticmethod</code>","text":"<pre><code>is_int32(t: ArrowSchemaExportable) -&gt; bool\n</code></pre>"},{"location":"api/core/datatype/#arro3.core.DataType.is_int64","title":"is_int64  <code>staticmethod</code>","text":"<pre><code>is_int64(t: ArrowSchemaExportable) -&gt; bool\n</code></pre>"},{"location":"api/core/datatype/#arro3.core.DataType.is_int8","title":"is_int8  <code>staticmethod</code>","text":"<pre><code>is_int8(t: ArrowSchemaExportable) -&gt; bool\n</code></pre>"},{"location":"api/core/datatype/#arro3.core.DataType.is_integer","title":"is_integer  <code>staticmethod</code>","text":"<pre><code>is_integer(t: ArrowSchemaExportable) -&gt; bool\n</code></pre>"},{"location":"api/core/datatype/#arro3.core.DataType.is_interval","title":"is_interval  <code>staticmethod</code>","text":"<pre><code>is_interval(t: ArrowSchemaExportable) -&gt; bool\n</code></pre>"},{"location":"api/core/datatype/#arro3.core.DataType.is_large_binary","title":"is_large_binary  <code>staticmethod</code>","text":"<pre><code>is_large_binary(t: ArrowSchemaExportable) -&gt; bool\n</code></pre>"},{"location":"api/core/datatype/#arro3.core.DataType.is_large_list","title":"is_large_list  <code>staticmethod</code>","text":"<pre><code>is_large_list(t: ArrowSchemaExportable) -&gt; bool\n</code></pre>"},{"location":"api/core/datatype/#arro3.core.DataType.is_large_list_view","title":"is_large_list_view  <code>staticmethod</code>","text":"<pre><code>is_large_list_view(t: ArrowSchemaExportable) -&gt; bool\n</code></pre>"},{"location":"api/core/datatype/#arro3.core.DataType.is_large_string","title":"is_large_string  <code>staticmethod</code>","text":"<pre><code>is_large_string(t: ArrowSchemaExportable) -&gt; bool\n</code></pre>"},{"location":"api/core/datatype/#arro3.core.DataType.is_large_unicode","title":"is_large_unicode  <code>staticmethod</code>","text":"<pre><code>is_large_unicode(t: ArrowSchemaExportable) -&gt; bool\n</code></pre>"},{"location":"api/core/datatype/#arro3.core.DataType.is_list","title":"is_list  <code>staticmethod</code>","text":"<pre><code>is_list(t: ArrowSchemaExportable) -&gt; bool\n</code></pre>"},{"location":"api/core/datatype/#arro3.core.DataType.is_list_view","title":"is_list_view  <code>staticmethod</code>","text":"<pre><code>is_list_view(t: ArrowSchemaExportable) -&gt; bool\n</code></pre>"},{"location":"api/core/datatype/#arro3.core.DataType.is_map","title":"is_map  <code>staticmethod</code>","text":"<pre><code>is_map(t: ArrowSchemaExportable) -&gt; bool\n</code></pre>"},{"location":"api/core/datatype/#arro3.core.DataType.is_nested","title":"is_nested  <code>staticmethod</code>","text":"<pre><code>is_nested(t: ArrowSchemaExportable) -&gt; bool\n</code></pre>"},{"location":"api/core/datatype/#arro3.core.DataType.is_null","title":"is_null  <code>staticmethod</code>","text":"<pre><code>is_null(t: ArrowSchemaExportable) -&gt; bool\n</code></pre>"},{"location":"api/core/datatype/#arro3.core.DataType.is_numeric","title":"is_numeric  <code>staticmethod</code>","text":"<pre><code>is_numeric(t: ArrowSchemaExportable) -&gt; bool\n</code></pre>"},{"location":"api/core/datatype/#arro3.core.DataType.is_primitive","title":"is_primitive  <code>staticmethod</code>","text":"<pre><code>is_primitive(t: ArrowSchemaExportable) -&gt; bool\n</code></pre>"},{"location":"api/core/datatype/#arro3.core.DataType.is_run_end_encoded","title":"is_run_end_encoded  <code>staticmethod</code>","text":"<pre><code>is_run_end_encoded(t: ArrowSchemaExportable) -&gt; bool\n</code></pre>"},{"location":"api/core/datatype/#arro3.core.DataType.is_signed_integer","title":"is_signed_integer  <code>staticmethod</code>","text":"<pre><code>is_signed_integer(t: ArrowSchemaExportable) -&gt; bool\n</code></pre>"},{"location":"api/core/datatype/#arro3.core.DataType.is_string","title":"is_string  <code>staticmethod</code>","text":"<pre><code>is_string(t: ArrowSchemaExportable) -&gt; bool\n</code></pre>"},{"location":"api/core/datatype/#arro3.core.DataType.is_string_view","title":"is_string_view  <code>staticmethod</code>","text":"<pre><code>is_string_view(t: ArrowSchemaExportable) -&gt; bool\n</code></pre>"},{"location":"api/core/datatype/#arro3.core.DataType.is_struct","title":"is_struct  <code>staticmethod</code>","text":"<pre><code>is_struct(t: ArrowSchemaExportable) -&gt; bool\n</code></pre>"},{"location":"api/core/datatype/#arro3.core.DataType.is_temporal","title":"is_temporal  <code>staticmethod</code>","text":"<pre><code>is_temporal(t: ArrowSchemaExportable) -&gt; bool\n</code></pre>"},{"location":"api/core/datatype/#arro3.core.DataType.is_time","title":"is_time  <code>staticmethod</code>","text":"<pre><code>is_time(t: ArrowSchemaExportable) -&gt; bool\n</code></pre>"},{"location":"api/core/datatype/#arro3.core.DataType.is_time32","title":"is_time32  <code>staticmethod</code>","text":"<pre><code>is_time32(t: ArrowSchemaExportable) -&gt; bool\n</code></pre>"},{"location":"api/core/datatype/#arro3.core.DataType.is_time64","title":"is_time64  <code>staticmethod</code>","text":"<pre><code>is_time64(t: ArrowSchemaExportable) -&gt; bool\n</code></pre>"},{"location":"api/core/datatype/#arro3.core.DataType.is_timestamp","title":"is_timestamp  <code>staticmethod</code>","text":"<pre><code>is_timestamp(t: ArrowSchemaExportable) -&gt; bool\n</code></pre>"},{"location":"api/core/datatype/#arro3.core.DataType.is_uint16","title":"is_uint16  <code>staticmethod</code>","text":"<pre><code>is_uint16(t: ArrowSchemaExportable) -&gt; bool\n</code></pre>"},{"location":"api/core/datatype/#arro3.core.DataType.is_uint32","title":"is_uint32  <code>staticmethod</code>","text":"<pre><code>is_uint32(t: ArrowSchemaExportable) -&gt; bool\n</code></pre>"},{"location":"api/core/datatype/#arro3.core.DataType.is_uint64","title":"is_uint64  <code>staticmethod</code>","text":"<pre><code>is_uint64(t: ArrowSchemaExportable) -&gt; bool\n</code></pre>"},{"location":"api/core/datatype/#arro3.core.DataType.is_uint8","title":"is_uint8  <code>staticmethod</code>","text":"<pre><code>is_uint8(t: ArrowSchemaExportable) -&gt; bool\n</code></pre>"},{"location":"api/core/datatype/#arro3.core.DataType.is_unicode","title":"is_unicode  <code>staticmethod</code>","text":"<pre><code>is_unicode(t: ArrowSchemaExportable) -&gt; bool\n</code></pre>"},{"location":"api/core/datatype/#arro3.core.DataType.is_union","title":"is_union  <code>staticmethod</code>","text":"<pre><code>is_union(t: ArrowSchemaExportable) -&gt; bool\n</code></pre>"},{"location":"api/core/datatype/#arro3.core.DataType.is_unsigned_integer","title":"is_unsigned_integer  <code>staticmethod</code>","text":"<pre><code>is_unsigned_integer(t: ArrowSchemaExportable) -&gt; bool\n</code></pre>"},{"location":"api/core/datatype/#arro3.core.DataType.large_binary","title":"large_binary  <code>builtin</code>","text":"<pre><code>large_binary() -&gt; DataType\n</code></pre> <p>Create large variable-length binary type.</p>"},{"location":"api/core/datatype/#arro3.core.DataType.large_list","title":"large_list  <code>builtin</code>","text":"<pre><code>large_list(value_type: ArrowSchemaExportable) -&gt; DataType\n</code></pre> <p>Create LargeListType instance from child data type or field.</p> <p>This data type may not be supported by all Arrow implementations. Unless you need to represent data larger than 2**31 elements, you should prefer <code>list()</code>.</p> <p>Parameters:</p> <ul> <li> <code>value_type</code>               (<code>ArrowSchemaExportable</code>)           \u2013            <p>description</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>DataType</code>           \u2013            <p>description</p> </li> </ul>"},{"location":"api/core/datatype/#arro3.core.DataType.large_list_view","title":"large_list_view  <code>builtin</code>","text":"<pre><code>large_list_view(value_type: ArrowSchemaExportable) -&gt; DataType\n</code></pre> <p>Create LargeListViewType instance from child data type or field.</p> <p>This data type may not be supported by all Arrow implementations because it is an alternative to the ListType.</p> <p>Parameters:</p> <ul> <li> <code>value_type</code>               (<code>ArrowSchemaExportable</code>)           \u2013            <p>description</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>DataType</code>           \u2013            <p>description</p> </li> </ul>"},{"location":"api/core/datatype/#arro3.core.DataType.large_string","title":"large_string  <code>builtin</code>","text":"<pre><code>large_string() -&gt; DataType\n</code></pre> <p>Create large UTF8 variable-length string type.</p>"},{"location":"api/core/datatype/#arro3.core.DataType.large_utf8","title":"large_utf8  <code>builtin</code>","text":"<pre><code>large_utf8() -&gt; DataType\n</code></pre> <p>Alias for large_string().</p>"},{"location":"api/core/datatype/#arro3.core.DataType.list","title":"list  <code>builtin</code>","text":"<pre><code>list(\n    value_type: ArrowSchemaExportable, list_size: int | None = None\n) -&gt; DataType\n</code></pre> <p>Create ListType instance from child data type or field.</p> <p>Parameters:</p> <ul> <li> <code>value_type</code>               (<code>ArrowSchemaExportable</code>)           \u2013            <p>description</p> </li> <li> <code>list_size</code>               (<code>int | None</code>, default:                   <code>None</code> )           \u2013            <p>If length is <code>None</code> then return a variable length list type. If length is provided then return a fixed size list type.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>DataType</code>           \u2013            <p>description</p> </li> </ul>"},{"location":"api/core/datatype/#arro3.core.DataType.list_view","title":"list_view  <code>builtin</code>","text":"<pre><code>list_view(value_type: ArrowSchemaExportable) -&gt; DataType\n</code></pre> <p>Create ListViewType instance from child data type or field.</p> <p>This data type may not be supported by all Arrow implementations because it is an alternative to the ListType.</p>"},{"location":"api/core/datatype/#arro3.core.DataType.map","title":"map  <code>builtin</code>","text":"<pre><code>map(\n    key_type: ArrowSchemaExportable,\n    item_type: ArrowSchemaExportable,\n    keys_sorted: bool,\n) -&gt; DataType\n</code></pre> <p>Create MapType instance from key and item data types or fields.</p> <p>Parameters:</p> <ul> <li> <code>key_type</code>               (<code>ArrowSchemaExportable</code>)           \u2013            <p>description</p> </li> <li> <code>item_type</code>               (<code>ArrowSchemaExportable</code>)           \u2013            <p>description</p> </li> <li> <code>keys_sorted</code>               (<code>bool</code>)           \u2013            <p>description</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>DataType</code>           \u2013            <p>description</p> </li> </ul>"},{"location":"api/core/datatype/#arro3.core.DataType.month_day_nano_interval","title":"month_day_nano_interval  <code>builtin</code>","text":"<pre><code>month_day_nano_interval() -&gt; DataType\n</code></pre> <p>Create instance of an interval type representing months, days and nanoseconds between two dates.</p>"},{"location":"api/core/datatype/#arro3.core.DataType.null","title":"null  <code>builtin</code>","text":"<pre><code>null() -&gt; DataType\n</code></pre> <p>Create instance of null type.</p>"},{"location":"api/core/datatype/#arro3.core.DataType.run_end_encoded","title":"run_end_encoded  <code>builtin</code>","text":"<pre><code>run_end_encoded(\n    run_end_type: ArrowSchemaExportable, value_type: ArrowSchemaExportable\n) -&gt; DataType\n</code></pre> <p>Create RunEndEncodedType from run-end and value types.</p> <p>Parameters:</p> <ul> <li> <code>run_end_type</code>               (<code>ArrowSchemaExportable</code>)           \u2013            <p>The integer type of the run_ends array. Must be <code>'int16'</code>, <code>'int32'</code>, or <code>'int64'</code>.</p> </li> <li> <code>value_type</code>               (<code>ArrowSchemaExportable</code>)           \u2013            <p>The type of the values array.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>DataType</code>           \u2013            <p>description</p> </li> </ul>"},{"location":"api/core/datatype/#arro3.core.DataType.string","title":"string  <code>builtin</code>","text":"<pre><code>string() -&gt; DataType\n</code></pre> <p>Create UTF8 variable-length string type.</p>"},{"location":"api/core/datatype/#arro3.core.DataType.string_view","title":"string_view  <code>builtin</code>","text":"<pre><code>string_view() -&gt; DataType\n</code></pre> <p>Create UTF8 variable-length string view type.</p>"},{"location":"api/core/datatype/#arro3.core.DataType.struct","title":"struct  <code>builtin</code>","text":"<pre><code>struct(fields: Sequence[ArrowSchemaExportable]) -&gt; DataType\n</code></pre> <p>Create StructType instance from fields.</p> <p>A struct is a nested type parameterized by an ordered sequence of types (which can all be distinct), called its fields.</p> <p>Parameters:</p> <ul> <li> <code>fields</code>               (<code>Sequence[ArrowSchemaExportable]</code>)           \u2013            <p>Each field must have a UTF8-encoded name, and these field names are part of the type metadata.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>DataType</code>           \u2013            <p>description</p> </li> </ul>"},{"location":"api/core/datatype/#arro3.core.DataType.time32","title":"time32  <code>builtin</code>","text":"<pre><code>time32(unit: Literal['s', 'ms']) -&gt; DataType\n</code></pre> <p>Create instance of 32-bit time (time of day) type with unit resolution.</p> <p>Parameters:</p> <ul> <li> <code>unit</code>               (<code>Literal['s', 'ms']</code>)           \u2013            <p>one of <code>'s'</code> [second], or <code>'ms'</code> [millisecond]</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>DataType</code>           \u2013            <p>description</p> </li> </ul>"},{"location":"api/core/datatype/#arro3.core.DataType.time64","title":"time64  <code>builtin</code>","text":"<pre><code>time64(unit: Literal['us', 'ns']) -&gt; DataType\n</code></pre> <p>Create instance of 64-bit time (time of day) type with unit resolution.</p> <p>Parameters:</p> <ul> <li> <code>unit</code>               (<code>Literal['us', 'ns']</code>)           \u2013            <p>One of <code>'us'</code> [microsecond], or <code>'ns'</code> [nanosecond].</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>DataType</code>           \u2013            <p>description</p> </li> </ul>"},{"location":"api/core/datatype/#arro3.core.DataType.timestamp","title":"timestamp  <code>builtin</code>","text":"<pre><code>timestamp(\n    unit: Literal[\"s\", \"ms\", \"us\", \"ns\"], *, tz: str | None = None\n) -&gt; DataType\n</code></pre> <p>Create instance of timestamp type with resolution and optional time zone.</p> <p>Parameters:</p> <ul> <li> <code>unit</code>               (<code>Literal['s', 'ms', 'us', 'ns']</code>)           \u2013            <p>one of <code>'s'</code> [second], <code>'ms'</code> [millisecond], <code>'us'</code> [microsecond], or <code>'ns'</code> [nanosecond]</p> </li> <li> <code>tz</code>               (<code>str | None</code>, default:                   <code>None</code> )           \u2013            <p>Time zone name. None indicates time zone naive. Defaults to None.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>DataType</code>           \u2013            <p>description</p> </li> </ul>"},{"location":"api/core/datatype/#arro3.core.DataType.uint16","title":"uint16  <code>builtin</code>","text":"<pre><code>uint16() -&gt; DataType\n</code></pre> <p>Create instance of unsigned int16 type.</p>"},{"location":"api/core/datatype/#arro3.core.DataType.uint32","title":"uint32  <code>builtin</code>","text":"<pre><code>uint32() -&gt; DataType\n</code></pre> <p>Create instance of unsigned int32 type.</p>"},{"location":"api/core/datatype/#arro3.core.DataType.uint64","title":"uint64  <code>builtin</code>","text":"<pre><code>uint64() -&gt; DataType\n</code></pre> <p>Create instance of unsigned int64 type.</p>"},{"location":"api/core/datatype/#arro3.core.DataType.uint8","title":"uint8  <code>builtin</code>","text":"<pre><code>uint8() -&gt; DataType\n</code></pre> <p>Create instance of unsigned int8 type.</p>"},{"location":"api/core/datatype/#arro3.core.DataType.utf8","title":"utf8  <code>builtin</code>","text":"<pre><code>utf8() -&gt; DataType\n</code></pre> <p>Alias for string().</p>"},{"location":"api/core/field/","title":"Field","text":""},{"location":"api/core/field/#arro3.core.Field","title":"arro3.core.Field","text":""},{"location":"api/core/field/#arro3.core.Field.metadata","title":"metadata","text":"<pre><code>metadata: dict[bytes, bytes] = &lt;attribute 'metadata' of 'arro3.core._core.Field' objects&gt;\n</code></pre>"},{"location":"api/core/field/#arro3.core.Field.metadata_str","title":"metadata_str","text":"<pre><code>metadata_str: dict[str, str] = &lt;attribute 'metadata_str' of 'arro3.core._core.Field' objects&gt;\n</code></pre>"},{"location":"api/core/field/#arro3.core.Field.name","title":"name","text":"<pre><code>name: str = &lt;attribute 'name' of 'arro3.core._core.Field' objects&gt;\n</code></pre>"},{"location":"api/core/field/#arro3.core.Field.nullable","title":"nullable","text":"<pre><code>nullable: bool = &lt;attribute 'nullable' of 'arro3.core._core.Field' objects&gt;\n</code></pre>"},{"location":"api/core/field/#arro3.core.Field.type","title":"type","text":"<pre><code>type: DataType = &lt;attribute 'type' of 'arro3.core._core.Field' objects&gt;\n</code></pre>"},{"location":"api/core/field/#arro3.core.Field.__arrow_c_schema__","title":"__arrow_c_schema__  <code>method descriptor</code>","text":"<pre><code>__arrow_c_schema__() -&gt; object\n</code></pre> <p>An implementation of the Arrow PyCapsule Interface. This dunder method should not be called directly, but enables zero-copy data transfer to other Python libraries that understand Arrow memory.</p> <p>For example, you can call <code>pyarrow.field()</code> to convert this array into a pyarrow field, without copying memory.</p>"},{"location":"api/core/field/#arro3.core.Field.equals","title":"equals  <code>method descriptor</code>","text":"<pre><code>equals(other: ArrowSchemaExportable) -&gt; bool\n</code></pre> <p>Test if this field is equal to the other.</p>"},{"location":"api/core/field/#arro3.core.Field.from_arrow","title":"from_arrow  <code>builtin</code>","text":"<pre><code>from_arrow(input: ArrowSchemaExportable) -&gt; Field\n</code></pre> <p>Construct this from an existing Arrow object.</p> <p>It can be called on anything that exports the Arrow schema interface (has an <code>__arrow_c_schema__</code> method).</p>"},{"location":"api/core/field/#arro3.core.Field.from_arrow_pycapsule","title":"from_arrow_pycapsule  <code>builtin</code>","text":"<pre><code>from_arrow_pycapsule(capsule) -&gt; Field\n</code></pre> <p>Construct this object from a bare Arrow PyCapsule</p>"},{"location":"api/core/field/#arro3.core.Field.remove_metadata","title":"remove_metadata  <code>method descriptor</code>","text":"<pre><code>remove_metadata() -&gt; Field\n</code></pre> <p>Create new field without metadata, if any.</p>"},{"location":"api/core/field/#arro3.core.Field.with_metadata","title":"with_metadata  <code>method descriptor</code>","text":"<pre><code>with_metadata(metadata: dict[str, str] | dict[bytes, bytes]) -&gt; Field\n</code></pre> <p>Add metadata as dict of string keys and values to Field.</p>"},{"location":"api/core/field/#arro3.core.Field.with_name","title":"with_name  <code>method descriptor</code>","text":"<pre><code>with_name(name: str) -&gt; Field\n</code></pre> <p>A copy of this field with the replaced name.</p>"},{"location":"api/core/field/#arro3.core.Field.with_nullable","title":"with_nullable  <code>method descriptor</code>","text":"<pre><code>with_nullable(nullable: bool) -&gt; Field\n</code></pre> <p>A copy of this field with the replaced nullability.</p>"},{"location":"api/core/field/#arro3.core.Field.with_type","title":"with_type  <code>method descriptor</code>","text":"<pre><code>with_type(new_type: ArrowSchemaExportable) -&gt; Field\n</code></pre> <p>A copy of this field with the replaced type</p>"},{"location":"api/core/record-batch-reader/","title":"RecordBatchReader","text":""},{"location":"api/core/record-batch-reader/#arro3.core.RecordBatchReader","title":"arro3.core.RecordBatchReader","text":"<p>An Arrow RecordBatchReader.</p> <p>A RecordBatchReader holds a stream of <code>RecordBatch</code>.</p>"},{"location":"api/core/record-batch-reader/#arro3.core.RecordBatchReader.closed","title":"closed","text":"<pre><code>closed: bool = &lt;attribute 'closed' of 'arro3.core._core.RecordBatchReader' objects&gt;\n</code></pre>"},{"location":"api/core/record-batch-reader/#arro3.core.RecordBatchReader.schema","title":"schema","text":"<pre><code>schema: Schema = &lt;attribute 'schema' of 'arro3.core._core.RecordBatchReader' objects&gt;\n</code></pre>"},{"location":"api/core/record-batch-reader/#arro3.core.RecordBatchReader.__arrow_c_stream__","title":"__arrow_c_stream__  <code>method descriptor</code>","text":"<pre><code>__arrow_c_stream__(requested_schema: object | None = None) -&gt; object\n</code></pre> <p>An implementation of the Arrow PyCapsule Interface. This dunder method should not be called directly, but enables zero-copy data transfer to other Python libraries that understand Arrow memory.</p> <p>For example, you can call <code>pyarrow.RecordBatchReader.from_stream</code> to convert this stream to a pyarrow <code>RecordBatchReader</code>. Alternatively, you can call <code>pyarrow.table()</code> to consume this stream to a pyarrow table or <code>Table.from_arrow()</code> to consume this stream to an arro3 Table.</p>"},{"location":"api/core/record-batch-reader/#arro3.core.RecordBatchReader.from_arrow","title":"from_arrow  <code>builtin</code>","text":"<pre><code>from_arrow(\n    input: ArrowArrayExportable | ArrowStreamExportable,\n) -&gt; RecordBatchReader\n</code></pre> <p>Construct this from an existing Arrow object.</p> <p>It can be called on anything that exports the Arrow stream interface (has an <code>__arrow_c_stream__</code> method), such as a <code>Table</code> or <code>RecordBatchReader</code>.</p>"},{"location":"api/core/record-batch-reader/#arro3.core.RecordBatchReader.from_arrow_pycapsule","title":"from_arrow_pycapsule  <code>builtin</code>","text":"<pre><code>from_arrow_pycapsule(capsule) -&gt; RecordBatchReader\n</code></pre> <p>Construct this object from a bare Arrow PyCapsule</p>"},{"location":"api/core/record-batch/","title":"RecordBatch","text":""},{"location":"api/core/record-batch/#arro3.core.RecordBatch","title":"arro3.core.RecordBatch","text":""},{"location":"api/core/record-batch/#arro3.core.RecordBatch.column_names","title":"column_names","text":"<pre><code>column_names: list[str] = &lt;attribute 'column_names' of 'arro3.core._core.RecordBatch' objects&gt;\n</code></pre>"},{"location":"api/core/record-batch/#arro3.core.RecordBatch.columns","title":"columns","text":"<pre><code>columns: list[Array] = &lt;attribute 'columns' of 'arro3.core._core.RecordBatch' objects&gt;\n</code></pre>"},{"location":"api/core/record-batch/#arro3.core.RecordBatch.nbytes","title":"nbytes","text":"<pre><code>nbytes: int = &lt;attribute 'nbytes' of 'arro3.core._core.RecordBatch' objects&gt;\n</code></pre>"},{"location":"api/core/record-batch/#arro3.core.RecordBatch.num_columns","title":"num_columns","text":"<pre><code>num_columns: int = &lt;attribute 'num_columns' of 'arro3.core._core.RecordBatch' objects&gt;\n</code></pre>"},{"location":"api/core/record-batch/#arro3.core.RecordBatch.num_rows","title":"num_rows","text":"<pre><code>num_rows: int = &lt;attribute 'num_rows' of 'arro3.core._core.RecordBatch' objects&gt;\n</code></pre>"},{"location":"api/core/record-batch/#arro3.core.RecordBatch.schema","title":"schema","text":"<pre><code>schema: Schema = &lt;attribute 'schema' of 'arro3.core._core.RecordBatch' objects&gt;\n</code></pre>"},{"location":"api/core/record-batch/#arro3.core.RecordBatch.shape","title":"shape","text":"<pre><code>shape: tuple[int, int] = &lt;attribute 'shape' of 'arro3.core._core.RecordBatch' objects&gt;\n</code></pre>"},{"location":"api/core/record-batch/#arro3.core.RecordBatch.__arrow_c_array__","title":"__arrow_c_array__  <code>method descriptor</code>","text":"<pre><code>__arrow_c_array__(\n    requested_schema: object | None = None,\n) -&gt; tuple[object, object]\n</code></pre> <p>An implementation of the Arrow PyCapsule Interface. This dunder method should not be called directly, but enables zero-copy data transfer to other Python libraries that understand Arrow memory.</p> <p>For example, you can call <code>pyarrow.record_batch()</code> to convert this RecordBatch into a pyarrow RecordBatch, without copying memory.</p>"},{"location":"api/core/record-batch/#arro3.core.RecordBatch.append_column","title":"append_column  <code>method descriptor</code>","text":"<pre><code>append_column(\n    field: str | ArrowSchemaExportable, column: ArrowArrayExportable\n) -&gt; RecordBatch\n</code></pre> <p>Append column at end of columns.</p> <p>Parameters:</p> <ul> <li> <code>field</code>               (<code>str | ArrowSchemaExportable</code>)           \u2013            <p>If a string is passed then the type is deduced from the column data.</p> </li> <li> <code>column</code>               (<code>ArrowArrayExportable</code>)           \u2013            <p>Column data</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RecordBatch</code>           \u2013            <p>description</p> </li> </ul>"},{"location":"api/core/record-batch/#arro3.core.RecordBatch.column","title":"column  <code>method descriptor</code>","text":"<pre><code>column(i: int | str) -&gt; ChunkedArray\n</code></pre> <p>Select single column from Table or RecordBatch.</p> <p>Parameters:</p> <ul> <li> <code>i</code>               (<code>int | str</code>)           \u2013            <p>The index or name of the column to retrieve.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ChunkedArray</code>           \u2013            <p>description</p> </li> </ul>"},{"location":"api/core/record-batch/#arro3.core.RecordBatch.equals","title":"equals  <code>method descriptor</code>","text":"<pre><code>equals(other: ArrowArrayExportable) -&gt; bool\n</code></pre> <p>Check if contents of two record batches are equal.</p> <p>Parameters:</p> <ul> <li> <code>other</code>               (<code>ArrowArrayExportable</code>)           \u2013            <p>RecordBatch to compare against.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bool</code>           \u2013            <p>description</p> </li> </ul>"},{"location":"api/core/record-batch/#arro3.core.RecordBatch.field","title":"field  <code>method descriptor</code>","text":"<pre><code>field(i: int | str) -&gt; Field\n</code></pre> <p>Select a schema field by its column name or numeric index.</p> <p>Parameters:</p> <ul> <li> <code>i</code>               (<code>int | str</code>)           \u2013            <p>The index or name of the field to retrieve.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Field</code>           \u2013            <p>description</p> </li> </ul>"},{"location":"api/core/record-batch/#arro3.core.RecordBatch.from_arrays","title":"from_arrays  <code>builtin</code>","text":"<pre><code>from_arrays(\n    arrays: Sequence[ArrowArrayExportable], *, schema: ArrowSchemaExportable\n) -&gt; RecordBatch\n</code></pre> <p>Construct a RecordBatch from multiple Arrays</p> <p>Parameters:</p> <ul> <li> <code>arrays</code>               (<code>Sequence[ArrowArrayExportable]</code>)           \u2013            <p>One for each field in RecordBatch</p> </li> <li> <code>schema</code>               (<code>ArrowSchemaExportable</code>)           \u2013            <p>Schema for the created batch. If not passed, names must be passed</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RecordBatch</code>           \u2013            <p>description</p> </li> </ul>"},{"location":"api/core/record-batch/#arro3.core.RecordBatch.from_arrow","title":"from_arrow  <code>builtin</code>","text":"<pre><code>from_arrow(input: ArrowArrayExportable | ArrowStreamExportable) -&gt; RecordBatch\n</code></pre> <p>Construct this from an existing Arrow RecordBatch.</p> <p>It can be called on anything that exports the Arrow data interface (has a <code>__arrow_c_array__</code> method) and returns a StructArray..</p> <p>Parameters:</p> <ul> <li> <code>input</code>               (<code>ArrowArrayExportable | ArrowStreamExportable</code>)           \u2013            <p>Arrow array to use for constructing this object</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RecordBatch</code>           \u2013            <p>new RecordBatch</p> </li> </ul>"},{"location":"api/core/record-batch/#arro3.core.RecordBatch.from_arrow_pycapsule","title":"from_arrow_pycapsule  <code>builtin</code>","text":"<pre><code>from_arrow_pycapsule(schema_capsule, array_capsule) -&gt; RecordBatch\n</code></pre> <p>Construct this object from bare Arrow PyCapsules</p>"},{"location":"api/core/record-batch/#arro3.core.RecordBatch.from_pydict","title":"from_pydict  <code>builtin</code>","text":"<pre><code>from_pydict(\n    mapping: dict[str, ArrowArrayExportable],\n    *,\n    metadata: ArrowSchemaExportable | None = None\n) -&gt; RecordBatch\n</code></pre> <p>Construct a Table or RecordBatch from Arrow arrays or columns.</p> <p>Parameters:</p> <ul> <li> <code>mapping</code>               (<code>dict[str, ArrowArrayExportable]</code>)           \u2013            <p>A mapping of strings to Arrays.</p> </li> <li> <code>metadata</code>               (<code>ArrowSchemaExportable | None</code>, default:                   <code>None</code> )           \u2013            <p>Optional metadata for the schema (if inferred). Defaults to None.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RecordBatch</code>           \u2013            <p>description</p> </li> </ul>"},{"location":"api/core/record-batch/#arro3.core.RecordBatch.from_struct_array","title":"from_struct_array  <code>builtin</code>","text":"<pre><code>from_struct_array(struct_array: ArrowArrayExportable) -&gt; RecordBatch\n</code></pre> <p>Construct a RecordBatch from a StructArray.</p> <p>Each field in the StructArray will become a column in the resulting RecordBatch.</p> <p>Parameters:</p> <ul> <li> <code>struct_array</code>               (<code>ArrowArrayExportable</code>)           \u2013            <p>Array to construct the record batch from.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RecordBatch</code>           \u2013            <p>New RecordBatch</p> </li> </ul>"},{"location":"api/core/record-batch/#arro3.core.RecordBatch.remove_column","title":"remove_column  <code>method descriptor</code>","text":"<pre><code>remove_column(i: int) -&gt; RecordBatch\n</code></pre> <p>Create new RecordBatch with the indicated column removed.</p> <p>Parameters:</p> <ul> <li> <code>i</code>               (<code>int</code>)           \u2013            <p>Index of column to remove.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RecordBatch</code>           \u2013            <p>New record batch without the column.</p> </li> </ul>"},{"location":"api/core/record-batch/#arro3.core.RecordBatch.select","title":"select  <code>method descriptor</code>","text":"<pre><code>select(columns: list[int] | list[str]) -&gt; RecordBatch\n</code></pre> <p>Select columns of the RecordBatch.</p> <p>Returns a new RecordBatch with the specified columns, and metadata preserved.</p> <p>Parameters:</p> <ul> <li> <code>columns</code>               (<code>list[int] | list[str]</code>)           \u2013            <p>The column names or integer indices to select.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RecordBatch</code>           \u2013            <p>New RecordBatch.</p> </li> </ul>"},{"location":"api/core/record-batch/#arro3.core.RecordBatch.set_column","title":"set_column  <code>method descriptor</code>","text":"<pre><code>set_column(\n    i: int, field: str | ArrowSchemaExportable, column: ArrowArrayExportable\n) -&gt; RecordBatch\n</code></pre> <p>Replace column in RecordBatch at position.</p> <p>Parameters:</p> <ul> <li> <code>i</code>               (<code>int</code>)           \u2013            <p>Index to place the column at.</p> </li> <li> <code>field</code>               (<code>str | ArrowSchemaExportable</code>)           \u2013            <p>If a string is passed then the type is deduced from the column data.</p> </li> <li> <code>column</code>               (<code>ArrowArrayExportable</code>)           \u2013            <p>Column data.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RecordBatch</code>           \u2013            <p>New RecordBatch.</p> </li> </ul>"},{"location":"api/core/record-batch/#arro3.core.RecordBatch.slice","title":"slice  <code>method descriptor</code>","text":"<pre><code>slice(offset: int = 0, length: int | None = None) -&gt; RecordBatch\n</code></pre> <p>Compute zero-copy slice of this RecordBatch</p> <p>Parameters:</p> <ul> <li> <code>offset</code>               (<code>int</code>, default:                   <code>0</code> )           \u2013            <p>Offset from start of record batch to slice. Defaults to 0.</p> </li> <li> <code>length</code>               (<code>int | None</code>, default:                   <code>None</code> )           \u2013            <p>Length of slice (default is until end of batch starting from offset). Defaults to None.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RecordBatch</code>           \u2013            <p>New RecordBatch.</p> </li> </ul>"},{"location":"api/core/record-batch/#arro3.core.RecordBatch.take","title":"take  <code>method descriptor</code>","text":"<pre><code>take(indices: ArrowArrayExportable) -&gt; RecordBatch\n</code></pre> <p>Select rows from a Table or RecordBatch.</p> <p>Parameters:</p> <ul> <li> <code>indices</code>               (<code>ArrowArrayExportable</code>)           \u2013            <p>The indices in the tabular object whose rows will be returned.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RecordBatch</code>           \u2013            <p>description</p> </li> </ul>"},{"location":"api/core/record-batch/#arro3.core.RecordBatch.to_struct_array","title":"to_struct_array  <code>method descriptor</code>","text":"<pre><code>to_struct_array() -&gt; Array\n</code></pre> <p>Convert to a struct array.</p> <p>Returns:</p> <ul> <li> <code>Array</code>           \u2013            <p>description</p> </li> </ul>"},{"location":"api/core/record-batch/#arro3.core.RecordBatch.with_schema","title":"with_schema  <code>method descriptor</code>","text":"<pre><code>with_schema(schema: ArrowSchemaExportable) -&gt; RecordBatch\n</code></pre> <p>Return a RecordBatch with the provided schema.</p>"},{"location":"api/core/schema/","title":"Schema","text":""},{"location":"api/core/schema/#arro3.core.Schema","title":"arro3.core.Schema","text":""},{"location":"api/core/schema/#arro3.core.Schema.metadata","title":"metadata","text":"<pre><code>metadata: dict[bytes, bytes] = &lt;attribute 'metadata' of 'arro3.core._core.Schema' objects&gt;\n</code></pre>"},{"location":"api/core/schema/#arro3.core.Schema.metadata_str","title":"metadata_str","text":"<pre><code>metadata_str: dict[str, str] = &lt;attribute 'metadata_str' of 'arro3.core._core.Schema' objects&gt;\n</code></pre>"},{"location":"api/core/schema/#arro3.core.Schema.names","title":"names","text":"<pre><code>names: list[str] = &lt;attribute 'names' of 'arro3.core._core.Schema' objects&gt;\n</code></pre>"},{"location":"api/core/schema/#arro3.core.Schema.types","title":"types","text":"<pre><code>types: list[DataType] = &lt;attribute 'types' of 'arro3.core._core.Schema' objects&gt;\n</code></pre>"},{"location":"api/core/schema/#arro3.core.Schema.__arrow_c_schema__","title":"__arrow_c_schema__  <code>method descriptor</code>","text":"<pre><code>__arrow_c_schema__() -&gt; object\n</code></pre> <p>An implementation of the Arrow PyCapsule Interface. This dunder method should not be called directly, but enables zero-copy data transfer to other Python libraries that understand Arrow memory.</p> <p>For example, you can call <code>pyarrow.schema()</code> to convert this array into a pyarrow schema, without copying memory.</p>"},{"location":"api/core/schema/#arro3.core.Schema.append","title":"append  <code>method descriptor</code>","text":"<pre><code>append(field: ArrowSchemaExportable) -&gt; Schema\n</code></pre> <p>Append a field at the end of the schema.</p> <p>In contrast to Python's <code>list.append()</code> it does return a new object, leaving the original Schema unmodified.</p> <p>Parameters:</p> <ul> <li> <code>field</code>               (<code>ArrowSchemaExportable</code>)           \u2013            <p>new field</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Schema</code>           \u2013            <p>New Schema</p> </li> </ul>"},{"location":"api/core/schema/#arro3.core.Schema.empty_table","title":"empty_table  <code>method descriptor</code>","text":"<pre><code>empty_table() -&gt; Table\n</code></pre> <p>Provide an empty table according to the schema.</p> <p>Returns:</p> <ul> <li> <code>Table</code>           \u2013            <p>Table</p> </li> </ul>"},{"location":"api/core/schema/#arro3.core.Schema.equals","title":"equals  <code>method descriptor</code>","text":"<pre><code>equals(other: ArrowSchemaExportable) -&gt; bool\n</code></pre> <p>Test if this schema is equal to the other</p> <p>Parameters:</p> <ul> <li> <code>other</code>               (<code>ArrowSchemaExportable</code>)           \u2013            <p>description</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bool</code>           \u2013            <p>description</p> </li> </ul>"},{"location":"api/core/schema/#arro3.core.Schema.field","title":"field  <code>method descriptor</code>","text":"<pre><code>field(i: int | str) -&gt; Field\n</code></pre> <p>Select a field by its column name or numeric index.</p> <p>Parameters:</p> <ul> <li> <code>i</code>               (<code>int | str</code>)           \u2013            <p>other</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Field</code>           \u2013            <p>description</p> </li> </ul>"},{"location":"api/core/schema/#arro3.core.Schema.from_arrow","title":"from_arrow  <code>builtin</code>","text":"<pre><code>from_arrow(input: ArrowSchemaExportable) -&gt; Schema\n</code></pre> <p>Construct this from an existing Arrow object</p> <p>Parameters:</p> <ul> <li> <code>input</code>               (<code>ArrowSchemaExportable</code>)           \u2013            <p>Arrow schema to use for constructing this object</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Schema</code>           \u2013            <p>description</p> </li> </ul>"},{"location":"api/core/schema/#arro3.core.Schema.from_arrow_pycapsule","title":"from_arrow_pycapsule  <code>builtin</code>","text":"<pre><code>from_arrow_pycapsule(capsule) -&gt; Schema\n</code></pre> <p>Construct this object from a bare Arrow PyCapsule</p>"},{"location":"api/core/schema/#arro3.core.Schema.get_all_field_indices","title":"get_all_field_indices  <code>method descriptor</code>","text":"<pre><code>get_all_field_indices(name: str) -&gt; list[int]\n</code></pre> <p>Return sorted list of indices for the fields with the given name.</p> <p>Parameters:</p> <ul> <li> <code>name</code>               (<code>str</code>)           \u2013            <p>description</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list[int]</code>           \u2013            <p>description</p> </li> </ul>"},{"location":"api/core/schema/#arro3.core.Schema.get_field_index","title":"get_field_index  <code>method descriptor</code>","text":"<pre><code>get_field_index(name: str) -&gt; int\n</code></pre> <p>Return index of the unique field with the given name.</p> <p>Parameters:</p> <ul> <li> <code>name</code>               (<code>str</code>)           \u2013            <p>description</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>int</code>           \u2013            <p>description</p> </li> </ul>"},{"location":"api/core/schema/#arro3.core.Schema.insert","title":"insert  <code>method descriptor</code>","text":"<pre><code>insert(i: int, field: ArrowSchemaExportable) -&gt; Schema\n</code></pre> <p>Add a field at position <code>i</code> to the schema.</p> <p>Parameters:</p> <ul> <li> <code>i</code>               (<code>int</code>)           \u2013            <p>description</p> </li> <li> <code>field</code>               (<code>ArrowSchemaExportable</code>)           \u2013            <p>description</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Schema</code>           \u2013            <p>description</p> </li> </ul>"},{"location":"api/core/schema/#arro3.core.Schema.remove","title":"remove  <code>method descriptor</code>","text":"<pre><code>remove(i: int) -&gt; Schema\n</code></pre> <p>Remove the field at index i from the schema.</p> <p>Parameters:</p> <ul> <li> <code>i</code>               (<code>int</code>)           \u2013            <p>description</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Schema</code>           \u2013            <p>description</p> </li> </ul>"},{"location":"api/core/schema/#arro3.core.Schema.remove_metadata","title":"remove_metadata  <code>method descriptor</code>","text":"<pre><code>remove_metadata() -&gt; Schema\n</code></pre> <p>Create new schema without metadata, if any</p> <p>Returns:</p> <ul> <li> <code>Schema</code>           \u2013            <p>description</p> </li> </ul>"},{"location":"api/core/schema/#arro3.core.Schema.set","title":"set  <code>method descriptor</code>","text":"<pre><code>set(i: int, field: ArrowSchemaExportable) -&gt; Schema\n</code></pre> <p>Replace a field at position <code>i</code> in the schema.</p> <p>Parameters:</p> <ul> <li> <code>i</code>               (<code>int</code>)           \u2013            <p>description</p> </li> <li> <code>field</code>               (<code>ArrowSchemaExportable</code>)           \u2013            <p>description</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Schema</code>           \u2013            <p>description</p> </li> </ul>"},{"location":"api/core/schema/#arro3.core.Schema.with_metadata","title":"with_metadata  <code>method descriptor</code>","text":"<pre><code>with_metadata(metadata: dict[str, str] | dict[bytes, bytes]) -&gt; Schema\n</code></pre> <p>Add metadata as dict of string keys and values to Schema.</p> <p>Parameters:</p> <ul> <li> <code>metadata</code>               (<code>dict[str, str] | dict[bytes, bytes]</code>)           \u2013            <p>description</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Schema</code>           \u2013            <p>description</p> </li> </ul>"},{"location":"api/core/table/","title":"Table","text":""},{"location":"api/core/table/#arro3.core.Table","title":"arro3.core.Table","text":"<p>A collection of top-level named, equal length Arrow arrays.</p>"},{"location":"api/core/table/#arro3.core.Table.chunk_lengths","title":"chunk_lengths","text":"<pre><code>chunk_lengths: list[int] = &lt;attribute 'chunk_lengths' of 'arro3.core._core.Table' objects&gt;\n</code></pre>"},{"location":"api/core/table/#arro3.core.Table.column_names","title":"column_names","text":"<pre><code>column_names: list[str] = &lt;attribute 'column_names' of 'arro3.core._core.Table' objects&gt;\n</code></pre>"},{"location":"api/core/table/#arro3.core.Table.columns","title":"columns","text":"<pre><code>columns: list[ChunkedArray] = &lt;attribute 'columns' of 'arro3.core._core.Table' objects&gt;\n</code></pre>"},{"location":"api/core/table/#arro3.core.Table.nbytes","title":"nbytes","text":"<pre><code>nbytes: int = &lt;attribute 'nbytes' of 'arro3.core._core.Table' objects&gt;\n</code></pre>"},{"location":"api/core/table/#arro3.core.Table.num_columns","title":"num_columns","text":"<pre><code>num_columns: int = &lt;attribute 'num_columns' of 'arro3.core._core.Table' objects&gt;\n</code></pre>"},{"location":"api/core/table/#arro3.core.Table.num_rows","title":"num_rows","text":"<pre><code>num_rows: int = &lt;attribute 'num_rows' of 'arro3.core._core.Table' objects&gt;\n</code></pre>"},{"location":"api/core/table/#arro3.core.Table.schema","title":"schema","text":"<pre><code>schema: Schema = &lt;attribute 'schema' of 'arro3.core._core.Table' objects&gt;\n</code></pre>"},{"location":"api/core/table/#arro3.core.Table.shape","title":"shape","text":"<pre><code>shape: tuple[int, int] = &lt;attribute 'shape' of 'arro3.core._core.Table' objects&gt;\n</code></pre>"},{"location":"api/core/table/#arro3.core.Table.__arrow_c_stream__","title":"__arrow_c_stream__  <code>method descriptor</code>","text":"<pre><code>__arrow_c_stream__(requested_schema: object | None = None) -&gt; object\n</code></pre> <p>An implementation of the Arrow PyCapsule Interface. This dunder method should not be called directly, but enables zero-copy data transfer to other Python libraries that understand Arrow memory.</p> <p>For example, you can call <code>pyarrow.table()</code> to convert this array into a pyarrow table, without copying memory.</p>"},{"location":"api/core/table/#arro3.core.Table.add_column","title":"add_column  <code>method descriptor</code>","text":"<pre><code>add_column(\n    i: int, field: str | ArrowSchemaExportable, column: ArrowStreamExportable\n) -&gt; Table\n</code></pre> <p>Add column to Table at position.</p> <p>A new table is returned with the column added, the original table object is left unchanged.</p> <p>Parameters:</p> <ul> <li> <code>i</code>               (<code>int</code>)           \u2013            <p>Index to place the column at.</p> </li> <li> <code>field</code>               (<code>str | ArrowSchemaExportable</code>)           \u2013            <p>description</p> </li> <li> <code>column</code>               (<code>ArrowStreamExportable</code>)           \u2013            <p>Column data.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Table</code>           \u2013            <p>New table with the passed column added.</p> </li> </ul>"},{"location":"api/core/table/#arro3.core.Table.append_column","title":"append_column  <code>method descriptor</code>","text":"<pre><code>append_column(\n    field: str | ArrowSchemaExportable, column: ArrowStreamExportable\n) -&gt; Table\n</code></pre> <p>Append column at end of columns.</p> <p>Parameters:</p> <ul> <li> <code>field</code>               (<code>str | ArrowSchemaExportable</code>)           \u2013            <p>description</p> </li> <li> <code>column</code>               (<code>ArrowStreamExportable</code>)           \u2013            <p>Column data.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Table</code>           \u2013            <p>New table or record batch with the passed column added.</p> </li> </ul>"},{"location":"api/core/table/#arro3.core.Table.column","title":"column  <code>method descriptor</code>","text":"<pre><code>column(i: int | str) -&gt; ChunkedArray\n</code></pre> <p>Select single column from Table or RecordBatch.</p> <p>Parameters:</p> <ul> <li> <code>i</code>               (<code>int | str</code>)           \u2013            <p>The index or name of the column to retrieve.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ChunkedArray</code>           \u2013            <p>description</p> </li> </ul>"},{"location":"api/core/table/#arro3.core.Table.combine_chunks","title":"combine_chunks  <code>method descriptor</code>","text":"<pre><code>combine_chunks() -&gt; Table\n</code></pre> <p>Make a new table by combining the chunks this table has.</p> <p>All the underlying chunks in the ChunkedArray of each column are concatenated into zero or one chunk.</p> <p>Returns:</p> <ul> <li> <code>Table</code>           \u2013            <p>new Table with one or zero chunks.</p> </li> </ul>"},{"location":"api/core/table/#arro3.core.Table.field","title":"field  <code>method descriptor</code>","text":"<pre><code>field(i: int | str) -&gt; Field\n</code></pre> <p>Select a schema field by its column name or numeric index.</p> <p>Parameters:</p> <ul> <li> <code>i</code>               (<code>int | str</code>)           \u2013            <p>The index or name of the field to retrieve.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Field</code>           \u2013            <p>description</p> </li> </ul>"},{"location":"api/core/table/#arro3.core.Table.from_arrays","title":"from_arrays  <code>builtin</code>","text":"<pre><code>from_arrays(\n    arrays: Sequence[ArrowArrayExportable | ArrowStreamExportable],\n    *,\n    names: Sequence[str] | None = None,\n    schema: ArrowSchemaExportable | None = None,\n    metadata: dict[str, str] | dict[bytes, bytes] | None = None\n) -&gt; Table\n</code></pre> <p>Construct a Table from Arrow arrays.</p> <p>Parameters:</p> <ul> <li> <code>arrays</code>               (<code>Sequence[ArrowArrayExportable | ArrowStreamExportable]</code>)           \u2013            <p>Equal-length arrays that should form the table.</p> </li> <li> <code>names</code>               (<code>Sequence[str] | None</code>, default:                   <code>None</code> )           \u2013            <p>Names for the table columns. If not passed, <code>schema</code> must be passed. Defaults to None.</p> </li> <li> <code>schema</code>               (<code>ArrowSchemaExportable | None</code>, default:                   <code>None</code> )           \u2013            <p>Schema for the created table. If not passed, <code>names</code> must be passed. Defaults to None.</p> </li> <li> <code>metadata</code>               (<code>dict[str, str] | dict[bytes, bytes] | None</code>, default:                   <code>None</code> )           \u2013            <p>Optional metadata for the schema (if inferred). Defaults to None.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Table</code>           \u2013            <p>new table</p> </li> </ul>"},{"location":"api/core/table/#arro3.core.Table.from_arrow","title":"from_arrow  <code>builtin</code>","text":"<pre><code>from_arrow(input: ArrowArrayExportable | ArrowStreamExportable) -&gt; Table\n</code></pre> <p>Construct this object from an existing Arrow object.</p> <p>It can be called on anything that exports the Arrow stream interface (<code>__arrow_c_stream__</code>) and yields a StructArray for each item. This Table will materialize all items from the iterator in memory at once. Use [<code>RecordBatchReader</code>] if you don't wish to materialize all batches in memory at once.</p> <p>Parameters:</p> <ul> <li> <code>input</code>               (<code>ArrowArrayExportable | ArrowStreamExportable</code>)           \u2013            <p>Arrow stream to use for constructing this object</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Table</code>           \u2013            <p>Self</p> </li> </ul>"},{"location":"api/core/table/#arro3.core.Table.from_arrow_pycapsule","title":"from_arrow_pycapsule  <code>builtin</code>","text":"<pre><code>from_arrow_pycapsule(capsule) -&gt; Table\n</code></pre> <p>Construct this object from a bare Arrow PyCapsule</p> <p>Parameters:</p> <ul> <li> <code>capsule</code>           \u2013            <p>description</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Table</code>           \u2013            <p>description</p> </li> </ul>"},{"location":"api/core/table/#arro3.core.Table.from_batches","title":"from_batches  <code>builtin</code>","text":"<pre><code>from_batches(\n    batches: Sequence[ArrowArrayExportable],\n    *,\n    schema: ArrowSchemaExportable | None = None\n) -&gt; Table\n</code></pre> <p>Construct a Table from a sequence of Arrow RecordBatches.</p> <p>Parameters:</p> <ul> <li> <code>batches</code>               (<code>Sequence[ArrowArrayExportable]</code>)           \u2013            <p>Sequence of RecordBatch to be converted, all schemas must be equal.</p> </li> <li> <code>schema</code>               (<code>ArrowSchemaExportable | None</code>, default:                   <code>None</code> )           \u2013            <p>If not passed, will be inferred from the first RecordBatch. Defaults to None.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Table</code>           \u2013            <p>New Table.</p> </li> </ul>"},{"location":"api/core/table/#arro3.core.Table.from_pydict","title":"from_pydict  <code>builtin</code>","text":"<pre><code>from_pydict(\n    mapping: dict[str, ArrowArrayExportable | ArrowStreamExportable],\n    *,\n    schema: ArrowSchemaExportable | None = None,\n    metadata: dict[str, str] | dict[bytes, bytes] | None = None\n) -&gt; Table\n</code></pre> <p>Construct a Table or RecordBatch from Arrow arrays or columns.</p> <p>Parameters:</p> <ul> <li> <code>mapping</code>               (<code>dict[str, ArrowArrayExportable | ArrowStreamExportable]</code>)           \u2013            <p>A mapping of strings to Arrays.</p> </li> <li> <code>schema</code>               (<code>ArrowSchemaExportable | None</code>, default:                   <code>None</code> )           \u2013            <p>If not passed, will be inferred from the Mapping values. Defaults to None.</p> </li> <li> <code>metadata</code>               (<code>dict[str, str] | dict[bytes, bytes] | None</code>, default:                   <code>None</code> )           \u2013            <p>Optional metadata for the schema (if inferred). Defaults to None.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Table</code>           \u2013            <p>new table</p> </li> </ul>"},{"location":"api/core/table/#arro3.core.Table.remove_column","title":"remove_column  <code>method descriptor</code>","text":"<pre><code>remove_column(i: int) -&gt; Table\n</code></pre> <p>Create new Table with the indicated column removed.</p> <p>Parameters:</p> <ul> <li> <code>i</code>               (<code>int</code>)           \u2013            <p>Index of column to remove.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Table</code>           \u2013            <p>New table without the column.</p> </li> </ul>"},{"location":"api/core/table/#arro3.core.Table.rename_columns","title":"rename_columns  <code>method descriptor</code>","text":"<pre><code>rename_columns(names: Sequence[str]) -&gt; Table\n</code></pre> <p>Create new table with columns renamed to provided names.</p> <p>Parameters:</p> <ul> <li> <code>names</code>               (<code>Sequence[str]</code>)           \u2013            <p>List of new column names.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Table</code>           \u2013            <p>description</p> </li> </ul>"},{"location":"api/core/table/#arro3.core.Table.select","title":"select  <code>method descriptor</code>","text":"<pre><code>select(columns: Sequence[int] | Sequence[str]) -&gt; Table\n</code></pre> <p>Select columns of the Table.</p> <p>Returns a new Table with the specified columns, and metadata preserved.</p> <p>Parameters:</p> <ul> <li> <code>columns</code>               (<code>Sequence[int] | Sequence[str]</code>)           \u2013            <p>The column names or integer indices to select.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Table</code>           \u2013            <p>description</p> </li> </ul>"},{"location":"api/core/table/#arro3.core.Table.set_column","title":"set_column  <code>method descriptor</code>","text":"<pre><code>set_column(\n    i: int, field: str | ArrowSchemaExportable, column: ArrowStreamExportable\n) -&gt; Table\n</code></pre> <p>Replace column in Table at position.</p> <p>Parameters:</p> <ul> <li> <code>i</code>               (<code>int</code>)           \u2013            <p>Index to place the column at.</p> </li> <li> <code>field</code>               (<code>str | ArrowSchemaExportable</code>)           \u2013            <p>description</p> </li> <li> <code>column</code>               (<code>ArrowStreamExportable</code>)           \u2013            <p>Column data.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Table</code>           \u2013            <p>description</p> </li> </ul>"},{"location":"api/core/table/#arro3.core.Table.to_batches","title":"to_batches  <code>method descriptor</code>","text":"<pre><code>to_batches() -&gt; list[RecordBatch]\n</code></pre> <p>Convert Table to a list of RecordBatch objects.</p> <p>Note that this method is zero-copy, it merely exposes the same data under a different API.</p> <p>Returns:</p> <ul> <li> <code>list[RecordBatch]</code>           \u2013            <p>description</p> </li> </ul>"},{"location":"api/core/table/#arro3.core.Table.to_reader","title":"to_reader  <code>method descriptor</code>","text":"<pre><code>to_reader() -&gt; RecordBatchReader\n</code></pre> <p>Convert the Table to a RecordBatchReader.</p> <p>Note that this method is zero-copy, it merely exposes the same data under a different API.</p> <p>Returns:</p> <ul> <li> <code>RecordBatchReader</code>           \u2013            <p>description</p> </li> </ul>"},{"location":"api/core/table/#arro3.core.Table.to_struct_array","title":"to_struct_array  <code>method descriptor</code>","text":"<pre><code>to_struct_array() -&gt; ChunkedArray\n</code></pre> <p>Convert to a chunked array of struct type.</p> <p>Returns:</p> <ul> <li> <code>ChunkedArray</code>           \u2013            <p>description</p> </li> </ul>"},{"location":"api/core/table/#arro3.core.Table.with_schema","title":"with_schema  <code>method descriptor</code>","text":"<pre><code>with_schema(schema: ArrowSchemaExportable) -&gt; Table\n</code></pre> <p>Assign a different schema onto this table.</p> <p>The new schema must be compatible with the existing data; this does not cast the underlying data to the new schema. This is primarily useful for changing the schema metadata.</p> <p>Parameters:</p> <ul> <li> <code>schema</code>               (<code>ArrowSchemaExportable</code>)           \u2013            <p>description</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Table</code>           \u2013            <p>description</p> </li> </ul>"},{"location":"api/core/types/","title":"types","text":""},{"location":"api/core/types/#arro3.core.types","title":"arro3.core.types","text":""},{"location":"api/core/types/#arro3.core.types.ArrowArrayExportable","title":"ArrowArrayExportable","text":"<p>               Bases: <code>Protocol</code></p> <p>An object with an <code>__arrow_c_array__</code> method.</p> <p>Supported objects include:</p> <ul> <li>arro3 <code>Array</code> or <code>RecordBatch</code> objects.</li> <li>pyarrow <code>Array</code> or <code>RecordBatch</code> objects</li> </ul> <p>Such an object implements the Arrow C Data Interface interface via the Arrow PyCapsule Interface. This allows for zero-copy Arrow data interchange across libraries.</p>"},{"location":"api/core/types/#arro3.core.types.ArrowArrayExportable.__arrow_c_array__","title":"__arrow_c_array__","text":"<pre><code>__arrow_c_array__(\n    requested_schema: object | None = None,\n) -&gt; Tuple[object, object]\n</code></pre>"},{"location":"api/core/types/#arro3.core.types.ArrowSchemaExportable","title":"ArrowSchemaExportable","text":"<p>               Bases: <code>Protocol</code></p> <p>An object with an <code>__arrow_c_schema__</code> method.</p> <p>Supported objects include:</p> <ul> <li>arro3 <code>Schema</code>, <code>Field</code>, or <code>DataType</code> objects.</li> <li>pyarrow <code>Schema</code>, <code>Field</code>, or <code>DataType</code> objects.</li> </ul> <p>Such an object implements the Arrow C Data Interface interface via the Arrow PyCapsule Interface. This allows for zero-copy Arrow data interchange across libraries.</p>"},{"location":"api/core/types/#arro3.core.types.ArrowSchemaExportable.__arrow_c_schema__","title":"__arrow_c_schema__","text":"<pre><code>__arrow_c_schema__() -&gt; object\n</code></pre>"},{"location":"api/core/types/#arro3.core.types.ArrowStreamExportable","title":"ArrowStreamExportable","text":"<p>               Bases: <code>Protocol</code></p> <p>An object with an <code>__arrow_c_stream__</code> method.</p> <p>Supported objects include:</p> <ul> <li>arro3 <code>Table</code>, <code>RecordBatchReader</code>, <code>ChunkedArray</code>, or <code>ArrayReader</code> objects.</li> <li>Polars <code>Series</code> or <code>DataFrame</code> objects (polars v1.2 or higher)</li> <li>pyarrow <code>RecordBatchReader</code>, <code>Table</code>, or <code>ChunkedArray</code> objects (pyarrow v14 or     higher)</li> <li>pandas <code>DataFrame</code>s  (pandas v2.2 or higher)</li> <li>ibis <code>Table</code> objects.</li> </ul> <p>For an up to date list of supported objects, see this issue.</p> <p>Such an object implements the Arrow C Stream interface via the Arrow PyCapsule Interface. This allows for zero-copy Arrow data interchange across libraries.</p>"},{"location":"api/core/types/#arro3.core.types.ArrowStreamExportable.__arrow_c_stream__","title":"__arrow_c_stream__","text":"<pre><code>__arrow_c_stream__(requested_schema: object | None = None) -&gt; object\n</code></pre>"}]}